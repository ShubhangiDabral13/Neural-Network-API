{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Data Processing For Neural Network Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Importing Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating two empty list.input data, the other will hold the target data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "train_samples = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data Creation\n",
    "\n",
    "As motivation for this data\n",
    "* letâ€™s suppose that an experimental drug was tested on individuals ranging from age 13 to 100 in a clinical trial.\n",
    "\n",
    "* The trial had 2100 participants. Half of the participants were under 65 years old, and the other half was 65 years of age or older.\n",
    "\n",
    "* The trial showed that around 95% of patients 65 or older experienced side effects from the drug, and around 95% of patients under 65 experienced no side effects, generally showing that elderly individuals were more likely to experience side effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    \n",
    "    # The ~5% of younger individuals who did experience side effects\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(1)\n",
    "    \n",
    "    # The ~5% of older individuals who did not experience side effects\n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "    \n",
    "for i in range(1000):\n",
    "    \n",
    "    # The ~95% of younger individuals who did not experience side effects\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "    # The ~95% of older individuals who did experience side effects\n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~The above code creates 2100 samples and stores the age of the individuals in the train_samples list and stores whether or not the individuals experienced side effects in the train_labels list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "76\n",
      "42\n",
      "71\n",
      "21\n",
      "71\n",
      "34\n",
      "100\n",
      "34\n",
      "78\n",
      "27\n",
      "99\n",
      "29\n",
      "90\n",
      "22\n",
      "96\n",
      "54\n",
      "81\n",
      "43\n",
      "83\n",
      "21\n",
      "67\n",
      "25\n",
      "68\n",
      "61\n",
      "92\n",
      "60\n",
      "86\n",
      "54\n",
      "69\n",
      "51\n",
      "100\n",
      "33\n",
      "87\n",
      "23\n",
      "69\n",
      "26\n",
      "95\n",
      "64\n",
      "73\n",
      "40\n",
      "87\n",
      "51\n",
      "95\n",
      "54\n",
      "94\n",
      "26\n",
      "82\n",
      "29\n",
      "94\n",
      "29\n",
      "79\n",
      "41\n",
      "99\n",
      "60\n",
      "89\n",
      "51\n",
      "81\n",
      "39\n",
      "67\n",
      "57\n",
      "87\n",
      "32\n",
      "91\n",
      "64\n",
      "72\n",
      "28\n",
      "70\n",
      "23\n",
      "91\n",
      "33\n",
      "82\n",
      "26\n",
      "85\n",
      "55\n",
      "77\n",
      "44\n",
      "65\n",
      "40\n",
      "66\n",
      "55\n",
      "90\n",
      "45\n",
      "91\n",
      "18\n",
      "83\n",
      "20\n",
      "78\n",
      "63\n",
      "87\n",
      "49\n",
      "87\n",
      "33\n",
      "72\n",
      "38\n",
      "99\n",
      "21\n",
      "85\n",
      "62\n",
      "68\n",
      "26\n",
      "90\n",
      "49\n",
      "94\n",
      "15\n",
      "78\n",
      "23\n",
      "98\n",
      "28\n",
      "69\n",
      "19\n",
      "76\n",
      "44\n",
      "94\n",
      "36\n",
      "99\n",
      "21\n",
      "79\n",
      "25\n",
      "66\n",
      "37\n",
      "96\n",
      "33\n",
      "77\n",
      "28\n",
      "77\n",
      "20\n",
      "72\n",
      "13\n",
      "95\n",
      "13\n",
      "69\n",
      "25\n",
      "70\n",
      "55\n",
      "98\n",
      "39\n",
      "87\n",
      "25\n",
      "85\n",
      "15\n",
      "71\n",
      "46\n",
      "65\n",
      "32\n",
      "94\n",
      "35\n",
      "97\n",
      "39\n",
      "79\n",
      "47\n",
      "73\n",
      "40\n",
      "88\n",
      "34\n",
      "86\n",
      "63\n",
      "73\n",
      "60\n",
      "78\n",
      "30\n",
      "97\n",
      "32\n",
      "79\n",
      "62\n",
      "99\n",
      "41\n",
      "72\n",
      "57\n",
      "95\n",
      "36\n",
      "73\n",
      "27\n",
      "85\n",
      "42\n",
      "66\n",
      "59\n",
      "96\n",
      "43\n",
      "83\n",
      "61\n",
      "68\n",
      "27\n",
      "92\n",
      "44\n",
      "92\n",
      "45\n",
      "79\n",
      "22\n",
      "67\n",
      "17\n",
      "75\n",
      "29\n",
      "78\n",
      "18\n",
      "70\n",
      "41\n",
      "73\n",
      "15\n",
      "100\n",
      "48\n",
      "74\n",
      "19\n",
      "86\n",
      "22\n",
      "90\n",
      "48\n",
      "81\n",
      "64\n",
      "94\n",
      "39\n",
      "94\n",
      "26\n",
      "71\n",
      "25\n",
      "90\n",
      "61\n",
      "77\n",
      "59\n",
      "72\n",
      "56\n",
      "95\n",
      "26\n",
      "88\n",
      "58\n",
      "73\n",
      "50\n",
      "86\n",
      "15\n",
      "89\n",
      "49\n",
      "77\n",
      "16\n",
      "96\n",
      "29\n",
      "68\n",
      "23\n",
      "69\n",
      "14\n",
      "69\n",
      "44\n",
      "97\n",
      "49\n",
      "100\n",
      "42\n",
      "79\n",
      "18\n",
      "75\n",
      "24\n",
      "67\n",
      "26\n",
      "67\n",
      "27\n",
      "68\n",
      "55\n",
      "77\n",
      "24\n",
      "67\n",
      "43\n",
      "99\n",
      "64\n",
      "78\n",
      "44\n",
      "100\n",
      "33\n",
      "93\n",
      "25\n",
      "96\n",
      "23\n",
      "73\n",
      "18\n",
      "86\n",
      "24\n",
      "74\n",
      "25\n",
      "86\n",
      "28\n",
      "68\n",
      "22\n",
      "89\n",
      "62\n",
      "81\n",
      "49\n",
      "97\n",
      "28\n",
      "81\n",
      "26\n",
      "80\n",
      "45\n",
      "76\n",
      "30\n",
      "66\n",
      "59\n",
      "85\n",
      "60\n",
      "99\n",
      "59\n",
      "65\n",
      "36\n",
      "77\n",
      "42\n",
      "84\n",
      "31\n",
      "95\n",
      "62\n",
      "77\n",
      "28\n",
      "80\n",
      "36\n",
      "98\n",
      "55\n",
      "99\n",
      "19\n",
      "92\n",
      "35\n",
      "91\n",
      "44\n",
      "99\n",
      "62\n",
      "98\n",
      "13\n",
      "92\n",
      "16\n",
      "86\n",
      "39\n",
      "72\n",
      "54\n",
      "65\n",
      "26\n",
      "87\n",
      "38\n",
      "90\n",
      "31\n",
      "100\n",
      "36\n",
      "85\n",
      "47\n",
      "100\n",
      "24\n",
      "94\n",
      "54\n",
      "65\n",
      "34\n",
      "75\n",
      "18\n",
      "81\n",
      "25\n",
      "87\n",
      "47\n",
      "96\n",
      "47\n",
      "87\n",
      "31\n",
      "93\n",
      "49\n",
      "91\n",
      "49\n",
      "87\n",
      "24\n",
      "100\n",
      "55\n",
      "68\n",
      "36\n",
      "90\n",
      "55\n",
      "86\n",
      "64\n",
      "77\n",
      "23\n",
      "72\n",
      "48\n",
      "82\n",
      "53\n",
      "92\n",
      "37\n",
      "68\n",
      "43\n",
      "73\n",
      "39\n",
      "91\n",
      "26\n",
      "87\n",
      "60\n",
      "70\n",
      "47\n",
      "87\n",
      "53\n",
      "69\n",
      "62\n",
      "75\n",
      "31\n",
      "69\n",
      "50\n",
      "88\n",
      "43\n",
      "66\n",
      "13\n",
      "76\n",
      "36\n",
      "88\n",
      "13\n",
      "86\n",
      "44\n",
      "80\n",
      "58\n",
      "87\n",
      "34\n",
      "96\n",
      "16\n",
      "82\n",
      "32\n",
      "67\n",
      "27\n",
      "93\n",
      "18\n",
      "88\n",
      "54\n",
      "76\n",
      "64\n",
      "86\n",
      "58\n",
      "70\n",
      "61\n",
      "92\n",
      "18\n",
      "83\n",
      "28\n",
      "100\n",
      "14\n",
      "92\n",
      "36\n",
      "70\n",
      "53\n",
      "80\n",
      "22\n",
      "98\n",
      "34\n",
      "82\n",
      "50\n",
      "77\n",
      "25\n",
      "69\n",
      "26\n",
      "78\n",
      "26\n",
      "93\n",
      "53\n",
      "83\n",
      "32\n",
      "88\n",
      "33\n",
      "98\n",
      "29\n",
      "98\n",
      "22\n",
      "65\n",
      "62\n",
      "71\n",
      "23\n",
      "72\n",
      "53\n",
      "86\n",
      "43\n",
      "68\n",
      "38\n",
      "99\n",
      "33\n",
      "76\n",
      "24\n",
      "96\n",
      "43\n",
      "87\n",
      "29\n",
      "92\n",
      "55\n",
      "82\n",
      "17\n",
      "66\n",
      "14\n",
      "73\n",
      "58\n",
      "83\n",
      "42\n",
      "88\n",
      "54\n",
      "95\n",
      "25\n",
      "84\n",
      "62\n",
      "100\n",
      "58\n",
      "78\n",
      "57\n",
      "88\n",
      "52\n",
      "78\n",
      "40\n",
      "80\n",
      "58\n",
      "85\n",
      "44\n",
      "85\n",
      "23\n",
      "98\n",
      "24\n",
      "94\n",
      "47\n",
      "83\n",
      "51\n",
      "67\n",
      "45\n",
      "85\n",
      "38\n",
      "93\n",
      "22\n",
      "85\n",
      "28\n",
      "100\n",
      "34\n",
      "71\n",
      "35\n",
      "81\n",
      "51\n",
      "65\n",
      "56\n",
      "95\n",
      "36\n",
      "82\n",
      "61\n",
      "98\n",
      "30\n",
      "77\n",
      "60\n",
      "75\n",
      "19\n",
      "75\n",
      "18\n",
      "89\n",
      "38\n",
      "82\n",
      "30\n",
      "100\n",
      "28\n",
      "66\n",
      "54\n",
      "83\n",
      "34\n",
      "80\n",
      "18\n",
      "76\n",
      "25\n",
      "66\n",
      "55\n",
      "100\n",
      "15\n",
      "66\n",
      "47\n",
      "94\n",
      "38\n",
      "81\n",
      "24\n",
      "99\n",
      "14\n",
      "100\n",
      "16\n",
      "100\n",
      "16\n",
      "83\n",
      "45\n",
      "95\n",
      "53\n",
      "80\n",
      "20\n",
      "95\n",
      "35\n",
      "69\n",
      "59\n",
      "74\n",
      "15\n",
      "68\n",
      "17\n",
      "84\n",
      "27\n",
      "80\n",
      "31\n",
      "77\n",
      "22\n",
      "98\n",
      "51\n",
      "87\n",
      "42\n",
      "67\n",
      "43\n",
      "91\n",
      "43\n",
      "80\n",
      "54\n",
      "96\n",
      "17\n",
      "96\n",
      "64\n",
      "81\n",
      "64\n",
      "71\n",
      "25\n",
      "71\n",
      "46\n",
      "97\n",
      "34\n",
      "70\n",
      "62\n",
      "76\n",
      "43\n",
      "95\n",
      "44\n",
      "90\n",
      "56\n",
      "78\n",
      "46\n",
      "79\n",
      "52\n",
      "100\n",
      "32\n",
      "70\n",
      "35\n",
      "84\n",
      "62\n",
      "90\n",
      "27\n",
      "76\n",
      "50\n",
      "78\n",
      "35\n",
      "85\n",
      "58\n",
      "84\n",
      "50\n",
      "67\n",
      "42\n",
      "92\n",
      "60\n",
      "98\n",
      "47\n",
      "98\n",
      "22\n",
      "76\n",
      "62\n",
      "68\n",
      "52\n",
      "89\n",
      "22\n",
      "87\n",
      "41\n",
      "86\n",
      "19\n",
      "77\n",
      "14\n",
      "67\n",
      "64\n",
      "77\n",
      "58\n",
      "80\n",
      "14\n",
      "85\n",
      "56\n",
      "100\n",
      "60\n",
      "71\n",
      "53\n",
      "85\n",
      "57\n",
      "86\n",
      "23\n",
      "73\n",
      "28\n",
      "86\n",
      "54\n",
      "94\n",
      "49\n",
      "88\n",
      "62\n",
      "83\n",
      "43\n",
      "85\n",
      "55\n",
      "66\n",
      "51\n",
      "77\n",
      "59\n",
      "66\n",
      "17\n",
      "75\n",
      "49\n",
      "71\n",
      "43\n",
      "84\n",
      "57\n",
      "73\n",
      "63\n",
      "65\n",
      "13\n",
      "82\n",
      "40\n",
      "94\n",
      "36\n",
      "97\n",
      "33\n",
      "78\n",
      "31\n",
      "66\n",
      "62\n",
      "85\n",
      "56\n",
      "94\n",
      "62\n",
      "72\n",
      "52\n",
      "84\n",
      "16\n",
      "82\n",
      "45\n",
      "86\n",
      "49\n",
      "97\n",
      "42\n",
      "73\n",
      "61\n",
      "68\n",
      "24\n",
      "72\n",
      "14\n",
      "95\n",
      "41\n",
      "65\n",
      "49\n",
      "96\n",
      "39\n",
      "84\n",
      "63\n",
      "86\n",
      "32\n",
      "77\n",
      "20\n",
      "97\n",
      "17\n",
      "97\n",
      "21\n",
      "85\n",
      "30\n",
      "82\n",
      "20\n",
      "68\n",
      "25\n",
      "89\n",
      "41\n",
      "86\n",
      "58\n",
      "91\n",
      "59\n",
      "75\n",
      "35\n",
      "79\n",
      "59\n",
      "98\n",
      "59\n",
      "96\n",
      "44\n",
      "66\n",
      "37\n",
      "83\n",
      "54\n",
      "91\n",
      "51\n",
      "73\n",
      "58\n",
      "86\n",
      "51\n",
      "89\n",
      "60\n",
      "85\n",
      "64\n",
      "70\n",
      "31\n",
      "75\n",
      "19\n",
      "79\n",
      "50\n",
      "97\n",
      "64\n",
      "80\n",
      "24\n",
      "68\n",
      "39\n",
      "90\n",
      "19\n",
      "70\n",
      "52\n",
      "66\n",
      "57\n",
      "99\n",
      "21\n",
      "77\n",
      "49\n",
      "80\n",
      "16\n",
      "91\n",
      "50\n",
      "66\n",
      "39\n",
      "94\n",
      "57\n",
      "92\n",
      "23\n",
      "97\n",
      "45\n",
      "87\n",
      "35\n",
      "92\n",
      "21\n",
      "70\n",
      "63\n",
      "83\n",
      "48\n",
      "81\n",
      "25\n",
      "95\n",
      "55\n",
      "100\n",
      "36\n",
      "76\n",
      "24\n",
      "69\n",
      "52\n",
      "87\n",
      "55\n",
      "67\n",
      "30\n",
      "75\n",
      "39\n",
      "98\n",
      "50\n",
      "89\n",
      "16\n",
      "68\n",
      "58\n",
      "78\n",
      "21\n",
      "100\n",
      "46\n",
      "68\n",
      "60\n",
      "90\n",
      "25\n",
      "65\n",
      "17\n",
      "88\n",
      "64\n",
      "89\n",
      "21\n",
      "94\n",
      "56\n",
      "92\n",
      "17\n",
      "90\n",
      "15\n",
      "91\n",
      "30\n",
      "87\n",
      "58\n",
      "99\n",
      "38\n",
      "80\n",
      "33\n",
      "67\n",
      "64\n",
      "81\n",
      "60\n",
      "74\n",
      "57\n",
      "88\n",
      "47\n",
      "85\n",
      "23\n",
      "91\n",
      "52\n",
      "78\n",
      "17\n",
      "67\n",
      "47\n",
      "99\n",
      "48\n",
      "88\n",
      "41\n",
      "85\n",
      "16\n",
      "72\n",
      "60\n",
      "84\n",
      "41\n",
      "80\n",
      "53\n",
      "86\n",
      "20\n",
      "77\n",
      "57\n",
      "99\n",
      "17\n",
      "84\n",
      "23\n",
      "82\n",
      "17\n",
      "88\n",
      "35\n",
      "74\n",
      "44\n",
      "96\n",
      "40\n",
      "88\n",
      "29\n",
      "65\n",
      "49\n",
      "98\n",
      "62\n",
      "86\n",
      "27\n",
      "85\n",
      "41\n",
      "82\n",
      "33\n",
      "99\n",
      "28\n",
      "66\n",
      "58\n",
      "95\n",
      "24\n",
      "68\n",
      "57\n",
      "70\n",
      "35\n",
      "95\n",
      "34\n",
      "74\n",
      "22\n",
      "95\n",
      "22\n",
      "87\n",
      "18\n",
      "95\n",
      "28\n",
      "94\n",
      "63\n",
      "68\n",
      "42\n",
      "65\n",
      "45\n",
      "81\n",
      "46\n",
      "85\n",
      "53\n",
      "86\n",
      "51\n",
      "69\n",
      "61\n",
      "83\n",
      "64\n",
      "99\n",
      "24\n",
      "96\n",
      "54\n",
      "66\n",
      "50\n",
      "91\n",
      "60\n",
      "76\n",
      "16\n",
      "90\n",
      "24\n",
      "99\n",
      "23\n",
      "70\n",
      "44\n",
      "71\n",
      "22\n",
      "74\n",
      "22\n",
      "73\n",
      "64\n",
      "81\n",
      "44\n",
      "89\n",
      "30\n",
      "75\n",
      "31\n",
      "66\n",
      "56\n",
      "96\n",
      "35\n",
      "76\n",
      "13\n",
      "72\n",
      "37\n",
      "75\n",
      "45\n",
      "100\n",
      "16\n",
      "97\n",
      "63\n",
      "72\n",
      "56\n",
      "91\n",
      "53\n",
      "76\n",
      "53\n",
      "73\n",
      "30\n",
      "84\n",
      "63\n",
      "78\n",
      "39\n",
      "79\n",
      "21\n",
      "99\n",
      "45\n",
      "66\n",
      "53\n",
      "74\n",
      "45\n",
      "72\n",
      "13\n",
      "87\n",
      "56\n",
      "93\n",
      "14\n",
      "95\n",
      "59\n",
      "73\n",
      "60\n",
      "77\n",
      "62\n",
      "99\n",
      "21\n",
      "100\n",
      "55\n",
      "79\n",
      "50\n",
      "89\n",
      "53\n",
      "83\n",
      "61\n",
      "85\n",
      "37\n",
      "93\n",
      "59\n",
      "83\n",
      "14\n",
      "98\n",
      "63\n",
      "72\n",
      "58\n",
      "78\n",
      "23\n",
      "78\n",
      "46\n",
      "65\n",
      "57\n",
      "88\n",
      "62\n",
      "90\n",
      "44\n",
      "89\n",
      "64\n",
      "83\n",
      "28\n",
      "87\n",
      "24\n",
      "92\n",
      "41\n",
      "72\n",
      "58\n",
      "65\n",
      "17\n",
      "97\n",
      "49\n",
      "78\n",
      "28\n",
      "88\n",
      "13\n",
      "72\n",
      "34\n",
      "67\n",
      "61\n",
      "67\n",
      "44\n",
      "74\n",
      "38\n",
      "93\n",
      "57\n",
      "90\n",
      "59\n",
      "99\n",
      "36\n",
      "92\n",
      "56\n",
      "73\n",
      "42\n",
      "95\n",
      "40\n",
      "74\n",
      "34\n",
      "92\n",
      "55\n",
      "98\n",
      "63\n",
      "100\n",
      "17\n",
      "83\n",
      "57\n",
      "83\n",
      "14\n",
      "74\n",
      "52\n",
      "84\n",
      "35\n",
      "90\n",
      "39\n",
      "73\n",
      "57\n",
      "93\n",
      "43\n",
      "74\n",
      "54\n",
      "84\n",
      "27\n",
      "96\n",
      "55\n",
      "100\n",
      "59\n",
      "92\n",
      "17\n",
      "81\n",
      "52\n",
      "71\n",
      "56\n",
      "72\n",
      "20\n",
      "100\n",
      "23\n",
      "92\n",
      "29\n",
      "74\n",
      "30\n",
      "92\n",
      "56\n",
      "90\n",
      "50\n",
      "69\n",
      "27\n",
      "88\n",
      "54\n",
      "88\n",
      "55\n",
      "66\n",
      "36\n",
      "97\n",
      "53\n",
      "95\n",
      "31\n",
      "89\n",
      "53\n",
      "77\n",
      "17\n",
      "82\n",
      "29\n",
      "96\n",
      "54\n",
      "89\n",
      "14\n",
      "88\n",
      "42\n",
      "65\n",
      "41\n",
      "69\n",
      "26\n",
      "93\n",
      "14\n",
      "85\n",
      "54\n",
      "92\n",
      "61\n",
      "65\n",
      "14\n",
      "76\n",
      "16\n",
      "66\n",
      "17\n",
      "67\n",
      "25\n",
      "87\n",
      "32\n",
      "91\n",
      "51\n",
      "73\n",
      "28\n",
      "86\n",
      "43\n",
      "69\n",
      "50\n",
      "65\n",
      "52\n",
      "94\n",
      "22\n",
      "97\n",
      "62\n",
      "81\n",
      "39\n",
      "69\n",
      "29\n",
      "78\n",
      "28\n",
      "74\n",
      "62\n",
      "100\n",
      "55\n",
      "79\n",
      "50\n",
      "70\n",
      "14\n",
      "92\n",
      "50\n",
      "68\n",
      "17\n",
      "81\n",
      "34\n",
      "75\n",
      "47\n",
      "99\n",
      "22\n",
      "73\n",
      "15\n",
      "88\n",
      "14\n",
      "83\n",
      "24\n",
      "94\n",
      "25\n",
      "79\n",
      "44\n",
      "99\n",
      "14\n",
      "73\n",
      "61\n",
      "77\n",
      "50\n",
      "66\n",
      "59\n",
      "68\n",
      "13\n",
      "91\n",
      "58\n",
      "80\n",
      "45\n",
      "86\n",
      "56\n",
      "88\n",
      "21\n",
      "78\n",
      "15\n",
      "81\n",
      "35\n",
      "72\n",
      "43\n",
      "76\n",
      "28\n",
      "70\n",
      "59\n",
      "99\n",
      "50\n",
      "69\n",
      "22\n",
      "82\n",
      "45\n",
      "99\n",
      "32\n",
      "74\n",
      "18\n",
      "94\n",
      "27\n",
      "71\n",
      "48\n",
      "94\n",
      "29\n",
      "93\n",
      "23\n",
      "74\n",
      "44\n",
      "75\n",
      "33\n",
      "84\n",
      "41\n",
      "67\n",
      "34\n",
      "78\n",
      "24\n",
      "93\n",
      "62\n",
      "95\n",
      "39\n",
      "78\n",
      "14\n",
      "99\n",
      "52\n",
      "81\n",
      "29\n",
      "83\n",
      "40\n",
      "69\n",
      "56\n",
      "65\n",
      "36\n",
      "96\n",
      "24\n",
      "67\n",
      "18\n",
      "74\n",
      "43\n",
      "78\n",
      "47\n",
      "65\n",
      "29\n",
      "96\n",
      "49\n",
      "93\n",
      "39\n",
      "99\n",
      "57\n",
      "68\n",
      "51\n",
      "86\n",
      "28\n",
      "76\n",
      "63\n",
      "65\n",
      "40\n",
      "96\n",
      "54\n",
      "79\n",
      "13\n",
      "68\n",
      "14\n",
      "67\n",
      "34\n",
      "76\n",
      "52\n",
      "90\n",
      "59\n",
      "78\n",
      "14\n",
      "85\n",
      "23\n",
      "100\n",
      "25\n",
      "81\n",
      "26\n",
      "67\n",
      "28\n",
      "67\n",
      "27\n",
      "94\n",
      "61\n",
      "79\n",
      "62\n",
      "99\n",
      "28\n",
      "85\n",
      "34\n",
      "91\n",
      "63\n",
      "80\n",
      "63\n",
      "100\n",
      "58\n",
      "66\n",
      "61\n",
      "98\n",
      "37\n",
      "84\n",
      "32\n",
      "79\n",
      "30\n",
      "75\n",
      "54\n",
      "70\n",
      "57\n",
      "73\n",
      "57\n",
      "88\n",
      "39\n",
      "92\n",
      "46\n",
      "73\n",
      "19\n",
      "79\n",
      "57\n",
      "99\n",
      "41\n",
      "79\n",
      "60\n",
      "98\n",
      "25\n",
      "73\n",
      "42\n",
      "70\n",
      "49\n",
      "92\n",
      "57\n",
      "76\n",
      "54\n",
      "70\n",
      "53\n",
      "74\n",
      "32\n",
      "93\n",
      "52\n",
      "90\n",
      "33\n",
      "97\n",
      "34\n",
      "80\n",
      "29\n",
      "81\n",
      "57\n",
      "70\n",
      "21\n",
      "92\n",
      "27\n",
      "76\n",
      "56\n",
      "84\n",
      "22\n",
      "92\n",
      "39\n",
      "92\n",
      "29\n",
      "85\n",
      "38\n",
      "82\n",
      "14\n",
      "83\n",
      "24\n",
      "83\n",
      "52\n",
      "74\n",
      "63\n",
      "88\n",
      "29\n",
      "100\n",
      "15\n",
      "74\n",
      "37\n",
      "79\n",
      "54\n",
      "74\n",
      "60\n",
      "74\n",
      "61\n",
      "71\n",
      "16\n",
      "100\n",
      "21\n",
      "76\n",
      "36\n",
      "78\n",
      "37\n",
      "92\n",
      "15\n",
      "89\n",
      "52\n",
      "86\n",
      "64\n",
      "68\n",
      "22\n",
      "79\n",
      "43\n",
      "73\n",
      "54\n",
      "82\n",
      "15\n",
      "67\n",
      "30\n",
      "96\n",
      "56\n",
      "72\n",
      "26\n",
      "93\n",
      "25\n",
      "69\n",
      "32\n",
      "70\n",
      "46\n",
      "84\n",
      "17\n",
      "86\n",
      "64\n",
      "77\n",
      "35\n",
      "89\n",
      "42\n",
      "93\n",
      "37\n",
      "73\n",
      "44\n",
      "97\n",
      "37\n",
      "77\n",
      "14\n",
      "99\n",
      "44\n",
      "69\n",
      "50\n",
      "90\n",
      "31\n",
      "89\n",
      "45\n",
      "88\n",
      "19\n",
      "73\n",
      "48\n",
      "89\n",
      "47\n",
      "81\n",
      "14\n",
      "73\n",
      "16\n",
      "87\n",
      "42\n",
      "94\n",
      "56\n",
      "85\n",
      "35\n",
      "99\n",
      "21\n",
      "65\n",
      "47\n",
      "100\n",
      "52\n",
      "73\n",
      "23\n",
      "70\n",
      "22\n",
      "83\n",
      "41\n",
      "92\n",
      "57\n",
      "84\n",
      "24\n",
      "80\n",
      "27\n",
      "93\n",
      "53\n",
      "85\n",
      "15\n",
      "86\n",
      "13\n",
      "69\n",
      "21\n",
      "94\n",
      "25\n",
      "70\n",
      "44\n",
      "99\n",
      "53\n",
      "77\n",
      "28\n",
      "65\n",
      "36\n",
      "74\n",
      "17\n",
      "75\n",
      "37\n",
      "78\n",
      "44\n",
      "87\n",
      "54\n",
      "92\n",
      "63\n",
      "83\n",
      "30\n",
      "76\n",
      "27\n",
      "91\n",
      "34\n",
      "100\n",
      "52\n",
      "69\n",
      "57\n",
      "99\n",
      "52\n",
      "96\n",
      "44\n",
      "98\n",
      "15\n",
      "68\n",
      "22\n",
      "96\n",
      "14\n",
      "100\n",
      "29\n",
      "88\n",
      "15\n",
      "81\n",
      "22\n",
      "92\n",
      "44\n",
      "100\n",
      "24\n",
      "85\n",
      "15\n",
      "83\n",
      "60\n",
      "92\n",
      "42\n",
      "97\n",
      "50\n",
      "83\n",
      "28\n",
      "73\n",
      "50\n",
      "94\n",
      "26\n",
      "95\n",
      "21\n",
      "75\n",
      "53\n",
      "76\n",
      "46\n",
      "81\n",
      "24\n",
      "65\n",
      "34\n",
      "66\n",
      "41\n",
      "85\n",
      "41\n",
      "77\n",
      "15\n",
      "96\n",
      "23\n",
      "77\n",
      "58\n",
      "84\n",
      "32\n",
      "79\n",
      "29\n",
      "77\n",
      "52\n",
      "71\n",
      "45\n",
      "74\n",
      "48\n",
      "95\n",
      "25\n",
      "89\n",
      "42\n",
      "98\n",
      "59\n",
      "98\n",
      "52\n",
      "91\n",
      "38\n",
      "84\n",
      "55\n",
      "84\n",
      "61\n",
      "70\n",
      "56\n",
      "91\n",
      "31\n",
      "69\n",
      "52\n",
      "81\n",
      "48\n",
      "68\n",
      "33\n",
      "88\n",
      "54\n",
      "85\n",
      "41\n",
      "75\n",
      "30\n",
      "96\n",
      "36\n",
      "69\n",
      "43\n",
      "70\n",
      "49\n",
      "69\n",
      "15\n",
      "94\n",
      "42\n",
      "69\n",
      "40\n",
      "82\n",
      "57\n",
      "96\n",
      "43\n",
      "70\n",
      "52\n",
      "99\n",
      "38\n",
      "70\n",
      "15\n",
      "91\n",
      "52\n",
      "73\n",
      "36\n",
      "71\n",
      "60\n",
      "95\n",
      "16\n",
      "70\n",
      "23\n",
      "66\n",
      "23\n",
      "74\n",
      "14\n",
      "99\n",
      "28\n",
      "65\n",
      "61\n",
      "99\n",
      "41\n",
      "73\n",
      "41\n",
      "96\n",
      "48\n",
      "69\n",
      "63\n",
      "75\n",
      "58\n",
      "90\n",
      "54\n",
      "96\n",
      "44\n",
      "90\n",
      "33\n",
      "88\n",
      "62\n",
      "86\n",
      "26\n",
      "77\n",
      "39\n",
      "69\n",
      "40\n",
      "86\n",
      "33\n",
      "76\n",
      "34\n",
      "92\n",
      "51\n",
      "82\n",
      "28\n",
      "96\n",
      "49\n",
      "98\n",
      "25\n",
      "72\n",
      "56\n",
      "83\n",
      "34\n",
      "74\n",
      "53\n",
      "68\n",
      "57\n",
      "80\n",
      "32\n",
      "88\n",
      "38\n",
      "68\n",
      "61\n",
      "70\n",
      "15\n",
      "84\n",
      "64\n",
      "96\n",
      "42\n",
      "97\n",
      "62\n",
      "67\n",
      "15\n",
      "98\n",
      "30\n",
      "82\n",
      "46\n",
      "83\n",
      "21\n",
      "80\n",
      "54\n",
      "96\n",
      "41\n",
      "98\n",
      "61\n",
      "65\n",
      "16\n",
      "73\n",
      "21\n",
      "100\n",
      "20\n",
      "66\n",
      "50\n",
      "87\n",
      "46\n",
      "80\n",
      "31\n",
      "79\n",
      "56\n",
      "69\n",
      "46\n",
      "70\n",
      "44\n",
      "82\n",
      "64\n",
      "99\n",
      "31\n",
      "97\n",
      "17\n",
      "97\n",
      "27\n",
      "97\n",
      "43\n",
      "66\n",
      "60\n",
      "69\n",
      "43\n",
      "94\n",
      "52\n",
      "69\n",
      "39\n",
      "80\n",
      "19\n",
      "86\n",
      "19\n",
      "85\n",
      "45\n",
      "70\n",
      "55\n",
      "77\n",
      "20\n",
      "81\n",
      "23\n",
      "77\n",
      "25\n",
      "77\n",
      "28\n",
      "91\n",
      "27\n",
      "96\n",
      "35\n",
      "94\n",
      "30\n",
      "65\n",
      "32\n",
      "72\n",
      "38\n",
      "78\n",
      "17\n",
      "88\n",
      "53\n",
      "68\n",
      "20\n",
      "89\n",
      "41\n",
      "75\n",
      "46\n",
      "96\n",
      "27\n",
      "67\n",
      "53\n",
      "82\n",
      "21\n",
      "93\n",
      "58\n",
      "88\n",
      "54\n",
      "85\n",
      "38\n",
      "66\n",
      "39\n",
      "85\n",
      "14\n",
      "71\n",
      "54\n",
      "67\n",
      "47\n",
      "65\n",
      "46\n",
      "80\n",
      "48\n",
      "83\n",
      "61\n",
      "67\n",
      "48\n",
      "69\n",
      "24\n",
      "71\n",
      "59\n",
      "97\n",
      "30\n",
      "76\n",
      "58\n",
      "75\n",
      "38\n",
      "99\n",
      "45\n",
      "98\n",
      "34\n",
      "71\n",
      "28\n",
      "100\n",
      "20\n",
      "75\n",
      "40\n",
      "100\n",
      "47\n",
      "79\n",
      "22\n",
      "91\n",
      "62\n",
      "71\n",
      "24\n",
      "96\n",
      "47\n",
      "99\n",
      "20\n",
      "73\n",
      "42\n",
      "73\n",
      "41\n",
      "77\n",
      "58\n",
      "81\n",
      "27\n",
      "95\n",
      "35\n",
      "98\n",
      "53\n",
      "97\n",
      "58\n",
      "100\n",
      "47\n",
      "65\n",
      "63\n",
      "82\n",
      "45\n",
      "89\n",
      "49\n",
      "94\n",
      "38\n",
      "90\n",
      "40\n",
      "76\n",
      "36\n",
      "71\n",
      "39\n",
      "76\n",
      "43\n",
      "68\n",
      "30\n",
      "90\n",
      "62\n",
      "85\n",
      "62\n",
      "97\n",
      "20\n",
      "76\n",
      "47\n",
      "99\n",
      "24\n",
      "91\n",
      "19\n",
      "88\n",
      "41\n",
      "66\n",
      "14\n",
      "86\n",
      "18\n",
      "79\n",
      "32\n",
      "93\n",
      "51\n",
      "91\n",
      "36\n",
      "88\n",
      "45\n",
      "81\n",
      "39\n",
      "83\n",
      "18\n",
      "97\n",
      "48\n",
      "85\n",
      "24\n",
      "90\n",
      "41\n",
      "87\n",
      "43\n",
      "78\n",
      "62\n",
      "82\n",
      "17\n",
      "76\n",
      "56\n",
      "67\n",
      "63\n",
      "98\n",
      "24\n",
      "98\n",
      "64\n",
      "87\n",
      "64\n",
      "80\n",
      "49\n",
      "84\n",
      "22\n",
      "81\n",
      "44\n",
      "70\n",
      "58\n",
      "84\n",
      "58\n",
      "93\n",
      "42\n",
      "79\n",
      "50\n",
      "73\n",
      "21\n",
      "73\n",
      "56\n",
      "77\n",
      "62\n",
      "85\n",
      "23\n",
      "93\n",
      "51\n",
      "82\n",
      "64\n",
      "67\n",
      "19\n",
      "78\n",
      "51\n",
      "99\n",
      "53\n",
      "86\n",
      "34\n",
      "77\n",
      "37\n",
      "98\n",
      "34\n",
      "67\n",
      "23\n",
      "90\n",
      "37\n",
      "81\n",
      "43\n",
      "86\n",
      "17\n",
      "97\n",
      "51\n",
      "85\n",
      "51\n",
      "73\n",
      "57\n",
      "69\n",
      "56\n",
      "71\n",
      "14\n",
      "68\n",
      "28\n",
      "99\n",
      "61\n",
      "72\n",
      "49\n",
      "66\n",
      "40\n",
      "93\n",
      "28\n",
      "69\n",
      "48\n",
      "80\n",
      "53\n",
      "73\n",
      "20\n",
      "91\n",
      "35\n",
      "80\n",
      "63\n",
      "70\n",
      "23\n",
      "86\n",
      "14\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "#Printing train_samples\n",
    "for i in train_samples:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#Printing train_labels \n",
    "for i in train_labels:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data Processing\n",
    "\n",
    "both list will be converted to numpy arrays.\n",
    "\n",
    "After that we will shuffle the arrays to reomve any oerder that was imposed on the data during the creationn process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels)\n",
    "train_samples = np.array(train_samples)\n",
    "train_labels, train_samples = shuffle(train_labels, train_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~We'll use scikit-learnâ€™s MinMaxScaler class to scale all of the data down from a scale ranging from 13 to 100 to be on a scale from 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_train_samples = scaler.fit_transform(train_samples.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~We reshape the data as a technical requirement just since the fit_transform() function doesnâ€™t accept 1D data by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11494253]\n",
      "[0.65517241]\n",
      "[0.06896552]\n",
      "[0.50574713]\n",
      "[0.89655172]\n",
      "[0.83908046]\n",
      "[0.88505747]\n",
      "[0.10344828]\n",
      "[0.14942529]\n",
      "[0.24137931]\n",
      "[0.67816092]\n",
      "[0.66666667]\n",
      "[0.85057471]\n",
      "[0.94252874]\n",
      "[0.94252874]\n",
      "[0.85057471]\n",
      "[0.82758621]\n",
      "[0.11494253]\n",
      "[0.81609195]\n",
      "[0.47126437]\n",
      "[0.56321839]\n",
      "[0.35632184]\n",
      "[0.8045977]\n",
      "[0.03448276]\n",
      "[0.95402299]\n",
      "[0.97701149]\n",
      "[0.62068966]\n",
      "[0.47126437]\n",
      "[0.44827586]\n",
      "[0.74712644]\n",
      "[0.10344828]\n",
      "[0.82758621]\n",
      "[0.89655172]\n",
      "[0.91954023]\n",
      "[0.97701149]\n",
      "[0.14942529]\n",
      "[0.09195402]\n",
      "[0.66666667]\n",
      "[0.14942529]\n",
      "[0.6091954]\n",
      "[0.40229885]\n",
      "[0.95402299]\n",
      "[0.67816092]\n",
      "[0.6091954]\n",
      "[0.09195402]\n",
      "[0.73563218]\n",
      "[0.85057471]\n",
      "[0.89655172]\n",
      "[0.94252874]\n",
      "[0.40229885]\n",
      "[0.79310345]\n",
      "[0.63218391]\n",
      "[0.06896552]\n",
      "[0.4137931]\n",
      "[0.02298851]\n",
      "[0.56321839]\n",
      "[0.77011494]\n",
      "[0.89655172]\n",
      "[0.32183908]\n",
      "[0.22988506]\n",
      "[0.04597701]\n",
      "[0.82758621]\n",
      "[0.70114943]\n",
      "[0.96551724]\n",
      "[0.96551724]\n",
      "[0.28735632]\n",
      "[0.63218391]\n",
      "[0.90804598]\n",
      "[0.68965517]\n",
      "[0.51724138]\n",
      "[0.33333333]\n",
      "[0.85057471]\n",
      "[0.85057471]\n",
      "[0.3908046]\n",
      "[0.85057471]\n",
      "[0.2183908]\n",
      "[0.7816092]\n",
      "[0.90804598]\n",
      "[0.96551724]\n",
      "[0.49425287]\n",
      "[0.34482759]\n",
      "[0.65517241]\n",
      "[0.51724138]\n",
      "[0.62068966]\n",
      "[0.88505747]\n",
      "[1.]\n",
      "[0.8045977]\n",
      "[0.89655172]\n",
      "[0.33333333]\n",
      "[0.54022989]\n",
      "[1.]\n",
      "[0.28735632]\n",
      "[0.3908046]\n",
      "[0.37931034]\n",
      "[0.56321839]\n",
      "[0.98850575]\n",
      "[0.36781609]\n",
      "[0.45977011]\n",
      "[0.49425287]\n",
      "[0.12643678]\n",
      "[0.47126437]\n",
      "[0.32183908]\n",
      "[0.12643678]\n",
      "[0.2183908]\n",
      "[0.48275862]\n",
      "[0.40229885]\n",
      "[0.83908046]\n",
      "[0.95402299]\n",
      "[0.65517241]\n",
      "[0.43678161]\n",
      "[0.55172414]\n",
      "[0.63218391]\n",
      "[0.47126437]\n",
      "[0.11494253]\n",
      "[0.75862069]\n",
      "[0.95402299]\n",
      "[0.]\n",
      "[0.09195402]\n",
      "[0.22988506]\n",
      "[0.68965517]\n",
      "[0.73563218]\n",
      "[0.49425287]\n",
      "[0.20689655]\n",
      "[0.88505747]\n",
      "[0.32183908]\n",
      "[0.6091954]\n",
      "[0.91954023]\n",
      "[0.44827586]\n",
      "[0.7816092]\n",
      "[0.73563218]\n",
      "[0.42528736]\n",
      "[0.16091954]\n",
      "[0.98850575]\n",
      "[0.42528736]\n",
      "[0.17241379]\n",
      "[0.36781609]\n",
      "[0.55172414]\n",
      "[0.48275862]\n",
      "[0.59770115]\n",
      "[0.22988506]\n",
      "[0.35632184]\n",
      "[0.90804598]\n",
      "[0.54022989]\n",
      "[0.44827586]\n",
      "[0.47126437]\n",
      "[0.77011494]\n",
      "[0.6091954]\n",
      "[0.65517241]\n",
      "[0.86206897]\n",
      "[0.90804598]\n",
      "[0.50574713]\n",
      "[0.17241379]\n",
      "[0.63218391]\n",
      "[0.81609195]\n",
      "[0.75862069]\n",
      "[0.14942529]\n",
      "[0.54022989]\n",
      "[0.79310345]\n",
      "[0.71264368]\n",
      "[0.44827586]\n",
      "[0.24137931]\n",
      "[0.25287356]\n",
      "[0.18390805]\n",
      "[0.62068966]\n",
      "[0.49425287]\n",
      "[0.11494253]\n",
      "[0.83908046]\n",
      "[0.75862069]\n",
      "[0.24137931]\n",
      "[0.97701149]\n",
      "[0.51724138]\n",
      "[0.93103448]\n",
      "[0.45977011]\n",
      "[0.97701149]\n",
      "[0.57471264]\n",
      "[0.83908046]\n",
      "[0.24137931]\n",
      "[0.1954023]\n",
      "[0.34482759]\n",
      "[0.09195402]\n",
      "[0.09195402]\n",
      "[0.98850575]\n",
      "[0.06896552]\n",
      "[0.59770115]\n",
      "[0.56321839]\n",
      "[0.18390805]\n",
      "[0.70114943]\n",
      "[0.29885057]\n",
      "[0.83908046]\n",
      "[0.18390805]\n",
      "[0.64367816]\n",
      "[0.89655172]\n",
      "[0.88505747]\n",
      "[0.93103448]\n",
      "[0.87356322]\n",
      "[0.59770115]\n",
      "[0.33333333]\n",
      "[0.8045977]\n",
      "[0.70114943]\n",
      "[0.98850575]\n",
      "[0.59770115]\n",
      "[0.79310345]\n",
      "[0.98850575]\n",
      "[0.5862069]\n",
      "[0.87356322]\n",
      "[0.32183908]\n",
      "[0.11494253]\n",
      "[0.86206897]\n",
      "[0.44827586]\n",
      "[0.95402299]\n",
      "[0.49425287]\n",
      "[0.6091954]\n",
      "[0.63218391]\n",
      "[0.73563218]\n",
      "[0.88505747]\n",
      "[0.34482759]\n",
      "[0.12643678]\n",
      "[0.1954023]\n",
      "[0.29885057]\n",
      "[0.34482759]\n",
      "[0.11494253]\n",
      "[0.50574713]\n",
      "[0.56321839]\n",
      "[0.7816092]\n",
      "[0.48275862]\n",
      "[0.56321839]\n",
      "[0.12643678]\n",
      "[0.12643678]\n",
      "[0.86206897]\n",
      "[0.22988506]\n",
      "[0.51724138]\n",
      "[0.11494253]\n",
      "[0.66666667]\n",
      "[0.86206897]\n",
      "[0.45977011]\n",
      "[0.24137931]\n",
      "[0.16091954]\n",
      "[0.70114943]\n",
      "[0.16091954]\n",
      "[0.47126437]\n",
      "[0.17241379]\n",
      "[0.06896552]\n",
      "[0.77011494]\n",
      "[0.63218391]\n",
      "[0.12643678]\n",
      "[0.97701149]\n",
      "[0.55172414]\n",
      "[0.72413793]\n",
      "[1.]\n",
      "[0.90804598]\n",
      "[0.97701149]\n",
      "[0.5862069]\n",
      "[0.85057471]\n",
      "[0.56321839]\n",
      "[0.66666667]\n",
      "[0.64367816]\n",
      "[0.2183908]\n",
      "[0.7816092]\n",
      "[0.45977011]\n",
      "[0.93103448]\n",
      "[0.11494253]\n",
      "[0.35632184]\n",
      "[0.64367816]\n",
      "[0.57471264]\n",
      "[0.8045977]\n",
      "[0.72413793]\n",
      "[0.20689655]\n",
      "[0.29885057]\n",
      "[0.91954023]\n",
      "[0.18390805]\n",
      "[0.11494253]\n",
      "[0.]\n",
      "[0.75862069]\n",
      "[0.91954023]\n",
      "[0.85057471]\n",
      "[0.5862069]\n",
      "[0.62068966]\n",
      "[0.89655172]\n",
      "[0.62068966]\n",
      "[0.81609195]\n",
      "[0.25287356]\n",
      "[0.4137931]\n",
      "[0.8045977]\n",
      "[0.14942529]\n",
      "[0.10344828]\n",
      "[0.82758621]\n",
      "[0.28735632]\n",
      "[0.75862069]\n",
      "[0.35632184]\n",
      "[0.97701149]\n",
      "[0.11494253]\n",
      "[0.24137931]\n",
      "[0.51724138]\n",
      "[0.03448276]\n",
      "[0.20689655]\n",
      "[0.98850575]\n",
      "[0.45977011]\n",
      "[0.51724138]\n",
      "[0.42528736]\n",
      "[0.04597701]\n",
      "[0.95402299]\n",
      "[0.74712644]\n",
      "[0.8045977]\n",
      "[0.57471264]\n",
      "[0.63218391]\n",
      "[0.97701149]\n",
      "[0.86206897]\n",
      "[0.50574713]\n",
      "[0.45977011]\n",
      "[0.44827586]\n",
      "[0.35632184]\n",
      "[0.44827586]\n",
      "[0.67816092]\n",
      "[0.90804598]\n",
      "[0.91954023]\n",
      "[0.44827586]\n",
      "[0.96551724]\n",
      "[0.70114943]\n",
      "[0.27586207]\n",
      "[0.05747126]\n",
      "[0.04597701]\n",
      "[0.55172414]\n",
      "[0.93103448]\n",
      "[0.96551724]\n",
      "[0.02298851]\n",
      "[0.10344828]\n",
      "[0.97701149]\n",
      "[0.68965517]\n",
      "[0.3908046]\n",
      "[0.87356322]\n",
      "[0.62068966]\n",
      "[0.51724138]\n",
      "[1.]\n",
      "[0.81609195]\n",
      "[0.08045977]\n",
      "[0.56321839]\n",
      "[0.]\n",
      "[0.49425287]\n",
      "[0.68965517]\n",
      "[0.65517241]\n",
      "[0.22988506]\n",
      "[0.85057471]\n",
      "[0.02298851]\n",
      "[0.81609195]\n",
      "[0.93103448]\n",
      "[0.08045977]\n",
      "[0.20689655]\n",
      "[0.79310345]\n",
      "[0.50574713]\n",
      "[0.88505747]\n",
      "[0.49425287]\n",
      "[0.3908046]\n",
      "[0.54022989]\n",
      "[0.47126437]\n",
      "[0.73563218]\n",
      "[0.27586207]\n",
      "[0.48275862]\n",
      "[0.2183908]\n",
      "[0.45977011]\n",
      "[0.01149425]\n",
      "[0.37931034]\n",
      "[0.64367816]\n",
      "[1.]\n",
      "[0.73563218]\n",
      "[0.47126437]\n",
      "[0.32183908]\n",
      "[0.87356322]\n",
      "[0.48275862]\n",
      "[0.48275862]\n",
      "[0.86206897]\n",
      "[0.68965517]\n",
      "[0.10344828]\n",
      "[0.98850575]\n",
      "[0.51724138]\n",
      "[0.98850575]\n",
      "[0.]\n",
      "[0.65517241]\n",
      "[0.10344828]\n",
      "[0.36781609]\n",
      "[0.57471264]\n",
      "[0.34482759]\n",
      "[0.96551724]\n",
      "[0.24137931]\n",
      "[0.32183908]\n",
      "[0.13793103]\n",
      "[0.85057471]\n",
      "[0.32183908]\n",
      "[0.]\n",
      "[0.71264368]\n",
      "[0.57471264]\n",
      "[0.09195402]\n",
      "[0.57471264]\n",
      "[0.63218391]\n",
      "[0.7816092]\n",
      "[0.88505747]\n",
      "[0.47126437]\n",
      "[0.43678161]\n",
      "[0.68965517]\n",
      "[0.68965517]\n",
      "[0.88505747]\n",
      "[0.]\n",
      "[0.7816092]\n",
      "[0.31034483]\n",
      "[0.82758621]\n",
      "[0.86206897]\n",
      "[0.56321839]\n",
      "[0.96551724]\n",
      "[0.74712644]\n",
      "[0.98850575]\n",
      "[0.31034483]\n",
      "[0.62068966]\n",
      "[0.51724138]\n",
      "[0.42528736]\n",
      "[0.62068966]\n",
      "[0.66666667]\n",
      "[0.5862069]\n",
      "[0.27586207]\n",
      "[0.34482759]\n",
      "[0.72413793]\n",
      "[0.82758621]\n",
      "[0.45977011]\n",
      "[0.45977011]\n",
      "[0.90804598]\n",
      "[0.94252874]\n",
      "[0.17241379]\n",
      "[0.43678161]\n",
      "[0.45977011]\n",
      "[0.98850575]\n",
      "[0.35632184]\n",
      "[0.8045977]\n",
      "[0.10344828]\n",
      "[0.06896552]\n",
      "[0.35632184]\n",
      "[0.97701149]\n",
      "[0.02298851]\n",
      "[0.79310345]\n",
      "[0.29885057]\n",
      "[0.55172414]\n",
      "[0.42528736]\n",
      "[0.45977011]\n",
      "[0.63218391]\n",
      "[0.70114943]\n",
      "[0.6091954]\n",
      "[0.98850575]\n",
      "[0.42528736]\n",
      "[0.73563218]\n",
      "[0.77011494]\n",
      "[0.25287356]\n",
      "[0.63218391]\n",
      "[0.49425287]\n",
      "[0.65517241]\n",
      "[0.17241379]\n",
      "[0.4137931]\n",
      "[0.81609195]\n",
      "[0.97701149]\n",
      "[0.02298851]\n",
      "[0.36781609]\n",
      "[0.97701149]\n",
      "[0.01149425]\n",
      "[0.4137931]\n",
      "[0.82758621]\n",
      "[0.8045977]\n",
      "[0.18390805]\n",
      "[0.68965517]\n",
      "[0.13793103]\n",
      "[0.17241379]\n",
      "[0.50574713]\n",
      "[0.59770115]\n",
      "[0.86206897]\n",
      "[0.97701149]\n",
      "[0.27586207]\n",
      "[0.03448276]\n",
      "[0.44827586]\n",
      "[0.68965517]\n",
      "[0.73563218]\n",
      "[0.70114943]\n",
      "[0.49425287]\n",
      "[0.11494253]\n",
      "[0.63218391]\n",
      "[0.79310345]\n",
      "[0.09195402]\n",
      "[0.82758621]\n",
      "[0.20689655]\n",
      "[0.4137931]\n",
      "[0.67816092]\n",
      "[0.01149425]\n",
      "[0.88505747]\n",
      "[0.85057471]\n",
      "[0.1954023]\n",
      "[0.98850575]\n",
      "[0.43678161]\n",
      "[0.14942529]\n",
      "[0.51724138]\n",
      "[0.64367816]\n",
      "[0.65517241]\n",
      "[0.45977011]\n",
      "[0.13793103]\n",
      "[0.1954023]\n",
      "[0.29885057]\n",
      "[1.]\n",
      "[0.4137931]\n",
      "[0.65517241]\n",
      "[0.63218391]\n",
      "[0.64367816]\n",
      "[0.26436782]\n",
      "[0.34482759]\n",
      "[0.73563218]\n",
      "[0.82758621]\n",
      "[0.52873563]\n",
      "[0.]\n",
      "[0.64367816]\n",
      "[0.05747126]\n",
      "[0.87356322]\n",
      "[0.17241379]\n",
      "[0.50574713]\n",
      "[0.35632184]\n",
      "[0.85057471]\n",
      "[0.59770115]\n",
      "[0.8045977]\n",
      "[0.68965517]\n",
      "[0.62068966]\n",
      "[0.04597701]\n",
      "[0.87356322]\n",
      "[0.48275862]\n",
      "[0.26436782]\n",
      "[0.63218391]\n",
      "[0.4137931]\n",
      "[0.42528736]\n",
      "[0.32183908]\n",
      "[0.94252874]\n",
      "[0.62068966]\n",
      "[0.47126437]\n",
      "[0.12643678]\n",
      "[0.95402299]\n",
      "[0.81609195]\n",
      "[0.05747126]\n",
      "[0.87356322]\n",
      "[0.6091954]\n",
      "[0.85057471]\n",
      "[0.1954023]\n",
      "[0.94252874]\n",
      "[0.40229885]\n",
      "[0.05747126]\n",
      "[0.8045977]\n",
      "[0.25287356]\n",
      "[0.25287356]\n",
      "[0.87356322]\n",
      "[0.71264368]\n",
      "[0.17241379]\n",
      "[0.81609195]\n",
      "[0.10344828]\n",
      "[0.34482759]\n",
      "[0.62068966]\n",
      "[0.67816092]\n",
      "[0.24137931]\n",
      "[0.72413793]\n",
      "[1.]\n",
      "[0.06896552]\n",
      "[0.62068966]\n",
      "[0.7816092]\n",
      "[0.70114943]\n",
      "[0.7816092]\n",
      "[0.33333333]\n",
      "[0.01149425]\n",
      "[0.37931034]\n",
      "[0.88505747]\n",
      "[0.70114943]\n",
      "[0.64367816]\n",
      "[0.98850575]\n",
      "[0.50574713]\n",
      "[0.22988506]\n",
      "[0.65517241]\n",
      "[0.90804598]\n",
      "[0.72413793]\n",
      "[0.94252874]\n",
      "[0.88505747]\n",
      "[0.93103448]\n",
      "[0.47126437]\n",
      "[0.44827586]\n",
      "[0.52873563]\n",
      "[0.83908046]\n",
      "[0.67816092]\n",
      "[0.35632184]\n",
      "[0.13793103]\n",
      "[0.4137931]\n",
      "[0.7816092]\n",
      "[0.91954023]\n",
      "[0.28735632]\n",
      "[0.42528736]\n",
      "[0.28735632]\n",
      "[0.02298851]\n",
      "[0.55172414]\n",
      "[0.11494253]\n",
      "[0.54022989]\n",
      "[0.1954023]\n",
      "[0.16091954]\n",
      "[0.87356322]\n",
      "[0.47126437]\n",
      "[0.6091954]\n",
      "[0.88505747]\n",
      "[0.59770115]\n",
      "[0.03448276]\n",
      "[0.68965517]\n",
      "[0.14942529]\n",
      "[0.63218391]\n",
      "[0.33333333]\n",
      "[0.7816092]\n",
      "[0.04597701]\n",
      "[0.44827586]\n",
      "[0.01149425]\n",
      "[0.65517241]\n",
      "[0.72413793]\n",
      "[0.8045977]\n",
      "[0.04597701]\n",
      "[0.48275862]\n",
      "[0.32183908]\n",
      "[0.10344828]\n",
      "[0.37931034]\n",
      "[0.10344828]\n",
      "[0.64367816]\n",
      "[0.6091954]\n",
      "[0.55172414]\n",
      "[0.05747126]\n",
      "[0.63218391]\n",
      "[0.52873563]\n",
      "[0.3908046]\n",
      "[0.1954023]\n",
      "[0.85057471]\n",
      "[0.90804598]\n",
      "[0.95402299]\n",
      "[0.12643678]\n",
      "[0.22988506]\n",
      "[0.65517241]\n",
      "[0.06896552]\n",
      "[0.14942529]\n",
      "[0.8045977]\n",
      "[0.3908046]\n",
      "[0.51724138]\n",
      "[0.56321839]\n",
      "[0.77011494]\n",
      "[0.8045977]\n",
      "[0.29885057]\n",
      "[0.93103448]\n",
      "[0.45977011]\n",
      "[0.24137931]\n",
      "[0.66666667]\n",
      "[0.29885057]\n",
      "[0.91954023]\n",
      "[0.64367816]\n",
      "[0.48275862]\n",
      "[0.5862069]\n",
      "[0.08045977]\n",
      "[0.6091954]\n",
      "[0.04597701]\n",
      "[0.71264368]\n",
      "[0.86206897]\n",
      "[0.49425287]\n",
      "[0.75862069]\n",
      "[0.40229885]\n",
      "[0.93103448]\n",
      "[0.16091954]\n",
      "[1.]\n",
      "[0.73563218]\n",
      "[0.14942529]\n",
      "[0.83908046]\n",
      "[0.62068966]\n",
      "[0.6091954]\n",
      "[0.03448276]\n",
      "[0.16091954]\n",
      "[1.]\n",
      "[0.5862069]\n",
      "[0.10344828]\n",
      "[0.64367816]\n",
      "[0.74712644]\n",
      "[0.73563218]\n",
      "[0.83908046]\n",
      "[0.31034483]\n",
      "[0.94252874]\n",
      "[0.11494253]\n",
      "[0.16091954]\n",
      "[0.5862069]\n",
      "[0.88505747]\n",
      "[0.47126437]\n",
      "[0.37931034]\n",
      "[0.98850575]\n",
      "[0.89655172]\n",
      "[0.7816092]\n",
      "[0.5862069]\n",
      "[0.55172414]\n",
      "[0.13793103]\n",
      "[0.71264368]\n",
      "[0.37931034]\n",
      "[0.36781609]\n",
      "[0.67816092]\n",
      "[0.93103448]\n",
      "[0.45977011]\n",
      "[0.8045977]\n",
      "[0.71264368]\n",
      "[0.33333333]\n",
      "[0.54022989]\n",
      "[0.93103448]\n",
      "[0.63218391]\n",
      "[0.10344828]\n",
      "[0.85057471]\n",
      "[0.54022989]\n",
      "[0.98850575]\n",
      "[0.83908046]\n",
      "[0.79310345]\n",
      "[0.34482759]\n",
      "[0.5862069]\n",
      "[0.45977011]\n",
      "[0.95402299]\n",
      "[0.43678161]\n",
      "[0.95402299]\n",
      "[0.68965517]\n",
      "[0.86206897]\n",
      "[0.06896552]\n",
      "[0.95402299]\n",
      "[0.7816092]\n",
      "[0.68965517]\n",
      "[0.18390805]\n",
      "[0.97701149]\n",
      "[0.33333333]\n",
      "[0.68965517]\n",
      "[0.89655172]\n",
      "[0.10344828]\n",
      "[0.98850575]\n",
      "[0.44827586]\n",
      "[0.91954023]\n",
      "[0.90804598]\n",
      "[0.08045977]\n",
      "[0.29885057]\n",
      "[0.16091954]\n",
      "[0.74712644]\n",
      "[0.43678161]\n",
      "[0.77011494]\n",
      "[0.48275862]\n",
      "[0.63218391]\n",
      "[0.95402299]\n",
      "[1.]\n",
      "[0.6091954]\n",
      "[0.17241379]\n",
      "[0.62068966]\n",
      "[0.98850575]\n",
      "[0.68965517]\n",
      "[0.70114943]\n",
      "[0.88505747]\n",
      "[0.87356322]\n",
      "[0.45977011]\n",
      "[0.75862069]\n",
      "[0.8045977]\n",
      "[0.01149425]\n",
      "[0.96551724]\n",
      "[0.5862069]\n",
      "[0.13793103]\n",
      "[0.22988506]\n",
      "[0.11494253]\n",
      "[0.87356322]\n",
      "[0.51724138]\n",
      "[0.42528736]\n",
      "[0.08045977]\n",
      "[0.91954023]\n",
      "[0.70114943]\n",
      "[0.28735632]\n",
      "[0.8045977]\n",
      "[0.94252874]\n",
      "[0.36781609]\n",
      "[0.75862069]\n",
      "[0.77011494]\n",
      "[0.96551724]\n",
      "[0.96551724]\n",
      "[0.48275862]\n",
      "[0.4137931]\n",
      "[0.75862069]\n",
      "[1.]\n",
      "[0.64367816]\n",
      "[0.74712644]\n",
      "[0.55172414]\n",
      "[0.35632184]\n",
      "[0.42528736]\n",
      "[0.98850575]\n",
      "[0.02298851]\n",
      "[0.98850575]\n",
      "[0.01149425]\n",
      "[0.16091954]\n",
      "[0.68965517]\n",
      "[0.66666667]\n",
      "[0.83908046]\n",
      "[0.77011494]\n",
      "[0.64367816]\n",
      "[0.90804598]\n",
      "[0.44827586]\n",
      "[0.64367816]\n",
      "[0.26436782]\n",
      "[0.57471264]\n",
      "[0.85057471]\n",
      "[0.55172414]\n",
      "[0.64367816]\n",
      "[0.09195402]\n",
      "[0.1954023]\n",
      "[0.73563218]\n",
      "[0.68965517]\n",
      "[0.34482759]\n",
      "[0.77011494]\n",
      "[0.74712644]\n",
      "[1.]\n",
      "[0.66666667]\n",
      "[0.02298851]\n",
      "[0.14942529]\n",
      "[0.98850575]\n",
      "[0.08045977]\n",
      "[0.13793103]\n",
      "[0.63218391]\n",
      "[0.09195402]\n",
      "[0.05747126]\n",
      "[0.12643678]\n",
      "[0.12643678]\n",
      "[0.62068966]\n",
      "[0.06896552]\n",
      "[0.86206897]\n",
      "[0.40229885]\n",
      "[0.18390805]\n",
      "[0.42528736]\n",
      "[0.65517241]\n",
      "[0.66666667]\n",
      "[0.72413793]\n",
      "[0.72413793]\n",
      "[0.86206897]\n",
      "[0.71264368]\n",
      "[0.12643678]\n",
      "[0.20689655]\n",
      "[0.50574713]\n",
      "[0.66666667]\n",
      "[0.22988506]\n",
      "[0.29885057]\n",
      "[0.17241379]\n",
      "[0.06896552]\n",
      "[0.12643678]\n",
      "[0.95402299]\n",
      "[0.51724138]\n",
      "[0.83908046]\n",
      "[0.56321839]\n",
      "[0.50574713]\n",
      "[0.77011494]\n",
      "[0.64367816]\n",
      "[0.90804598]\n",
      "[0.68965517]\n",
      "[0.31034483]\n",
      "[0.72413793]\n",
      "[0.81609195]\n",
      "[0.75862069]\n",
      "[0.82758621]\n",
      "[0.01149425]\n",
      "[0.62068966]\n",
      "[0.97701149]\n",
      "[0.12643678]\n",
      "[0.74712644]\n",
      "[0.52873563]\n",
      "[0.51724138]\n",
      "[0.79310345]\n",
      "[0.88505747]\n",
      "[0.62068966]\n",
      "[0.25287356]\n",
      "[0.98850575]\n",
      "[0.36781609]\n",
      "[0.24137931]\n",
      "[0.50574713]\n",
      "[0.71264368]\n",
      "[0.64367816]\n",
      "[0.86206897]\n",
      "[0.47126437]\n",
      "[0.25287356]\n",
      "[0.40229885]\n",
      "[0.13793103]\n",
      "[0.02298851]\n",
      "[0.31034483]\n",
      "[0.47126437]\n",
      "[0.01149425]\n",
      "[0.8045977]\n",
      "[0.04597701]\n",
      "[0.71264368]\n",
      "[0.72413793]\n",
      "[0.09195402]\n",
      "[0.88505747]\n",
      "[0.09195402]\n",
      "[0.01149425]\n",
      "[0.72413793]\n",
      "[0.24137931]\n",
      "[0.56321839]\n",
      "[0.67816092]\n",
      "[0.65517241]\n",
      "[0.40229885]\n",
      "[0.]\n",
      "[0.71264368]\n",
      "[0.01149425]\n",
      "[0.90804598]\n",
      "[0.98850575]\n",
      "[0.56321839]\n",
      "[0.74712644]\n",
      "[0.71264368]\n",
      "[0.01149425]\n",
      "[0.32183908]\n",
      "[0.89655172]\n",
      "[1.]\n",
      "[0.93103448]\n",
      "[0.27586207]\n",
      "[0.67816092]\n",
      "[0.50574713]\n",
      "[0.17241379]\n",
      "[0.73563218]\n",
      "[0.6091954]\n",
      "[0.56321839]\n",
      "[0.59770115]\n",
      "[0.86206897]\n",
      "[0.89655172]\n",
      "[0.83908046]\n",
      "[0.49425287]\n",
      "[0.85057471]\n",
      "[0.52873563]\n",
      "[0.49425287]\n",
      "[0.42528736]\n",
      "[0.66666667]\n",
      "[0.79310345]\n",
      "[0.67816092]\n",
      "[0.94252874]\n",
      "[0.1954023]\n",
      "[0.6091954]\n",
      "[0.35632184]\n",
      "[0.59770115]\n",
      "[0.77011494]\n",
      "[0.26436782]\n",
      "[0.56321839]\n",
      "[0.81609195]\n",
      "[0.7816092]\n",
      "[0.74712644]\n",
      "[0.44827586]\n",
      "[0.67816092]\n",
      "[0.42528736]\n",
      "[0.68965517]\n",
      "[0.34482759]\n",
      "[0.93103448]\n",
      "[0.74712644]\n",
      "[0.94252874]\n",
      "[0.52873563]\n",
      "[0.73563218]\n",
      "[0.73563218]\n",
      "[0.6091954]\n",
      "[0.70114943]\n",
      "[0.83908046]\n",
      "[0.67816092]\n",
      "[0.26436782]\n",
      "[0.52873563]\n",
      "[0.36781609]\n",
      "[0.96551724]\n",
      "[0.01149425]\n",
      "[0.77011494]\n",
      "[0.29885057]\n",
      "[0.51724138]\n",
      "[0.96551724]\n",
      "[0.68965517]\n",
      "[0.43678161]\n",
      "[0.34482759]\n",
      "[0.22988506]\n",
      "[0.17241379]\n",
      "[0.72413793]\n",
      "[0.91954023]\n",
      "[0.29885057]\n",
      "[0.68965517]\n",
      "[0.52873563]\n",
      "[0.56321839]\n",
      "[0.29885057]\n",
      "[0.82758621]\n",
      "[0.17241379]\n",
      "[0.13793103]\n",
      "[0.47126437]\n",
      "[0.48275862]\n",
      "[0.08045977]\n",
      "[0.4137931]\n",
      "[0.04597701]\n",
      "[0.20689655]\n",
      "[0.18390805]\n",
      "[0.12643678]\n",
      "[0.64367816]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77011494]\n",
      "[0.42528736]\n",
      "[0.96551724]\n",
      "[0.28735632]\n",
      "[0.87356322]\n",
      "[0.3908046]\n",
      "[0.57471264]\n",
      "[0.48275862]\n",
      "[0.81609195]\n",
      "[0.42528736]\n",
      "[0.13793103]\n",
      "[0.96551724]\n",
      "[0.97701149]\n",
      "[0.98850575]\n",
      "[0.71264368]\n",
      "[0.33333333]\n",
      "[0.44827586]\n",
      "[0.62068966]\n",
      "[0.8045977]\n",
      "[0.35632184]\n",
      "[0.04597701]\n",
      "[1.]\n",
      "[0.75862069]\n",
      "[0.48275862]\n",
      "[0.90804598]\n",
      "[0.32183908]\n",
      "[0.59770115]\n",
      "[0.73563218]\n",
      "[0.97701149]\n",
      "[0.72413793]\n",
      "[0.22988506]\n",
      "[0.98850575]\n",
      "[0.70114943]\n",
      "[0.5862069]\n",
      "[0.79310345]\n",
      "[0.40229885]\n",
      "[0.8045977]\n",
      "[0.25287356]\n",
      "[0.98850575]\n",
      "[0.81609195]\n",
      "[0.11494253]\n",
      "[0.29885057]\n",
      "[0.98850575]\n",
      "[0.11494253]\n",
      "[0.74712644]\n",
      "[0.10344828]\n",
      "[0.93103448]\n",
      "[0.3908046]\n",
      "[0.7816092]\n",
      "[0.50574713]\n",
      "[0.5862069]\n",
      "[0.7816092]\n",
      "[0.17241379]\n",
      "[0.17241379]\n",
      "[0.28735632]\n",
      "[0.85057471]\n",
      "[0.4137931]\n",
      "[0.68965517]\n",
      "[0.35632184]\n",
      "[0.83908046]\n",
      "[0.56321839]\n",
      "[0.82758621]\n",
      "[0.94252874]\n",
      "[0.68965517]\n",
      "[0.13793103]\n",
      "[0.01149425]\n",
      "[0.55172414]\n",
      "[0.4137931]\n",
      "[0.64367816]\n",
      "[0.16091954]\n",
      "[0.47126437]\n",
      "[0.32183908]\n",
      "[0.74712644]\n",
      "[0.16091954]\n",
      "[0.72413793]\n",
      "[0.96551724]\n",
      "[0.43678161]\n",
      "[0.08045977]\n",
      "[0.75862069]\n",
      "[0.35632184]\n",
      "[0.54022989]\n",
      "[0.16091954]\n",
      "[0.54022989]\n",
      "[0.31034483]\n",
      "[0.82758621]\n",
      "[0.98850575]\n",
      "[0.79310345]\n",
      "[0.45977011]\n",
      "[0.37931034]\n",
      "[0.45977011]\n",
      "[0.24137931]\n",
      "[0.01149425]\n",
      "[0.03448276]\n",
      "[0.63218391]\n",
      "[0.4137931]\n",
      "[0.98850575]\n",
      "[0.90804598]\n",
      "[1.]\n",
      "[0.8045977]\n",
      "[0.17241379]\n",
      "[0.72413793]\n",
      "[0.65517241]\n",
      "[0.11494253]\n",
      "[0.79310345]\n",
      "[0.89655172]\n",
      "[0.63218391]\n",
      "[0.26436782]\n",
      "[0.83908046]\n",
      "[0.93103448]\n",
      "[0.82758621]\n",
      "[0.6091954]\n",
      "[0.65517241]\n",
      "[0.85057471]\n",
      "[0.79310345]\n",
      "[0.96551724]\n",
      "[0.2183908]\n",
      "[0.82758621]\n",
      "[0.77011494]\n",
      "[0.93103448]\n",
      "[0.43678161]\n",
      "[0.13793103]\n",
      "[0.87356322]\n",
      "[0.62068966]\n",
      "[0.16091954]\n",
      "[0.67816092]\n",
      "[0.74712644]\n",
      "[0.03448276]\n",
      "[0.26436782]\n",
      "[0.87356322]\n",
      "[0.83908046]\n",
      "[0.73563218]\n",
      "[0.05747126]\n",
      "[0.06896552]\n",
      "[0.90804598]\n",
      "[0.77011494]\n",
      "[0.82758621]\n",
      "[0.89655172]\n",
      "[0.86206897]\n",
      "[0.97701149]\n",
      "[0.24137931]\n",
      "[0.10344828]\n",
      "[0.83908046]\n",
      "[0.73563218]\n",
      "[0.13793103]\n",
      "[0.4137931]\n",
      "[0.70114943]\n",
      "[0.16091954]\n",
      "[0.83908046]\n",
      "[0.72413793]\n",
      "[0.10344828]\n",
      "[0.50574713]\n",
      "[0.02298851]\n",
      "[0.93103448]\n",
      "[0.90804598]\n",
      "[0.36781609]\n",
      "[0.08045977]\n",
      "[0.82758621]\n",
      "[0.49425287]\n",
      "[0.26436782]\n",
      "[0.68965517]\n",
      "[0.82758621]\n",
      "[0.50574713]\n",
      "[0.16091954]\n",
      "[0.71264368]\n",
      "[0.08045977]\n",
      "[0.81609195]\n",
      "[0.05747126]\n",
      "[0.12643678]\n",
      "[0.83908046]\n",
      "[0.05747126]\n",
      "[0.65517241]\n",
      "[0.12643678]\n",
      "[0.52873563]\n",
      "[0.4137931]\n",
      "[0.75862069]\n",
      "[0.11494253]\n",
      "[0.56321839]\n",
      "[0.89655172]\n",
      "[0.3908046]\n",
      "[0.95402299]\n",
      "[0.70114943]\n",
      "[0.12643678]\n",
      "[0.26436782]\n",
      "[0.81609195]\n",
      "[0.50574713]\n",
      "[0.34482759]\n",
      "[0.17241379]\n",
      "[0.70114943]\n",
      "[0.25287356]\n",
      "[0.05747126]\n",
      "[1.]\n",
      "[0.64367816]\n",
      "[0.83908046]\n",
      "[0.5862069]\n",
      "[0.14942529]\n",
      "[0.35632184]\n",
      "[0.36781609]\n",
      "[0.52873563]\n",
      "[0.79310345]\n",
      "[0.7816092]\n",
      "[0.33333333]\n",
      "[0.93103448]\n",
      "[0.25287356]\n",
      "[0.36781609]\n",
      "[0.75862069]\n",
      "[0.75862069]\n",
      "[1.]\n",
      "[0.24137931]\n",
      "[0.77011494]\n",
      "[0.95402299]\n",
      "[0.6091954]\n",
      "[0.34482759]\n",
      "[0.26436782]\n",
      "[1.]\n",
      "[0.89655172]\n",
      "[0.82758621]\n",
      "[0.95402299]\n",
      "[0.8045977]\n",
      "[0.96551724]\n",
      "[0.81609195]\n",
      "[0.12643678]\n",
      "[0.6091954]\n",
      "[0.57471264]\n",
      "[0.54022989]\n",
      "[0.17241379]\n",
      "[0.24137931]\n",
      "[0.27586207]\n",
      "[0.64367816]\n",
      "[0.95402299]\n",
      "[0.35632184]\n",
      "[0.75862069]\n",
      "[0.97701149]\n",
      "[0.64367816]\n",
      "[0.05747126]\n",
      "[0.3908046]\n",
      "[0.96551724]\n",
      "[0.97701149]\n",
      "[0.95402299]\n",
      "[0.89655172]\n",
      "[0.90804598]\n",
      "[0.63218391]\n",
      "[0.5862069]\n",
      "[0.67816092]\n",
      "[0.66666667]\n",
      "[0.35632184]\n",
      "[0.16091954]\n",
      "[0.04597701]\n",
      "[0.57471264]\n",
      "[0.86206897]\n",
      "[0.32183908]\n",
      "[0.4137931]\n",
      "[0.37931034]\n",
      "[0.1954023]\n",
      "[0.59770115]\n",
      "[0.59770115]\n",
      "[0.12643678]\n",
      "[0.03448276]\n",
      "[0.20689655]\n",
      "[0.56321839]\n",
      "[0.72413793]\n",
      "[0.5862069]\n",
      "[0.02298851]\n",
      "[0.04597701]\n",
      "[0.6091954]\n",
      "[0.28735632]\n",
      "[0.47126437]\n",
      "[0.56321839]\n",
      "[0.51724138]\n",
      "[0.33333333]\n",
      "[0.75862069]\n",
      "[0.94252874]\n",
      "[0.86206897]\n",
      "[0.32183908]\n",
      "[0.77011494]\n",
      "[0.36781609]\n",
      "[0.01149425]\n",
      "[0.70114943]\n",
      "[0.34482759]\n",
      "[0.59770115]\n",
      "[0.56321839]\n",
      "[0.56321839]\n",
      "[0.44827586]\n",
      "[0.24137931]\n",
      "[0.17241379]\n",
      "[0.]\n",
      "[0.04597701]\n",
      "[0.3908046]\n",
      "[0.73563218]\n",
      "[0.85057471]\n",
      "[0.54022989]\n",
      "[0.35632184]\n",
      "[0.02298851]\n",
      "[0.49425287]\n",
      "[0.59770115]\n",
      "[0.86206897]\n",
      "[0.36781609]\n",
      "[0.71264368]\n",
      "[0.71264368]\n",
      "[0.55172414]\n",
      "[0.37931034]\n",
      "[0.02298851]\n",
      "[0.47126437]\n",
      "[0.12643678]\n",
      "[0.88505747]\n",
      "[0.6091954]\n",
      "[0.22988506]\n",
      "[0.45977011]\n",
      "[0.82758621]\n",
      "[0.7816092]\n",
      "[0.43678161]\n",
      "[0.56321839]\n",
      "[0.14942529]\n",
      "[0.32183908]\n",
      "[0.18390805]\n",
      "[0.09195402]\n",
      "[0.3908046]\n",
      "[0.51724138]\n",
      "[0.88505747]\n",
      "[0.88505747]\n",
      "[0.12643678]\n",
      "[0.54022989]\n",
      "[0.7816092]\n",
      "[0.64367816]\n",
      "[0.52873563]\n",
      "[0.72413793]\n",
      "[0.79310345]\n",
      "[0.29885057]\n",
      "[0.14942529]\n",
      "[0.71264368]\n",
      "[0.90804598]\n",
      "[0.66666667]\n",
      "[0.3908046]\n",
      "[0.22988506]\n",
      "[0.63218391]\n",
      "[0.70114943]\n",
      "[0.93103448]\n",
      "[0.35632184]\n",
      "[0.63218391]\n",
      "[0.74712644]\n",
      "[0.68965517]\n",
      "[0.74712644]\n",
      "[0.5862069]\n",
      "[0.13793103]\n",
      "[0.65517241]\n",
      "[0.88505747]\n",
      "[0.91954023]\n",
      "[0.37931034]\n",
      "[0.74712644]\n",
      "[0.42528736]\n",
      "[0.73563218]\n",
      "[0.91954023]\n",
      "[0.32183908]\n",
      "[0.66666667]\n",
      "[0.63218391]\n",
      "[0.86206897]\n",
      "[0.71264368]\n",
      "[0.29885057]\n",
      "[0.66666667]\n",
      "[0.28735632]\n",
      "[0.67816092]\n",
      "[0.51724138]\n",
      "[0.18390805]\n",
      "[0.94252874]\n",
      "[0.83908046]\n",
      "[0.62068966]\n",
      "[0.49425287]\n",
      "[0.44827586]\n",
      "[0.29885057]\n",
      "[0.55172414]\n",
      "[1.]\n",
      "[0.24137931]\n",
      "[0.25287356]\n",
      "[0.10344828]\n",
      "[0.7816092]\n",
      "[0.74712644]\n",
      "[0.43678161]\n",
      "[0.03448276]\n",
      "[0.82758621]\n",
      "[0.51724138]\n",
      "[0.70114943]\n",
      "[0.64367816]\n",
      "[0.59770115]\n",
      "[0.20689655]\n",
      "[0.98850575]\n",
      "[0.02298851]\n",
      "[0.47126437]\n",
      "[0.04597701]\n",
      "[0.73563218]\n",
      "[0.71264368]\n",
      "[0.50574713]\n",
      "[0.91954023]\n",
      "[0.03448276]\n",
      "[0.74712644]\n",
      "[0.08045977]\n",
      "[0.89655172]\n",
      "[0.11494253]\n",
      "[0.55172414]\n",
      "[0.26436782]\n",
      "[0.96551724]\n",
      "[0.82758621]\n",
      "[0.32183908]\n",
      "[1.]\n",
      "[0.5862069]\n",
      "[0.8045977]\n",
      "[0.72413793]\n",
      "[0.79310345]\n",
      "[0.4137931]\n",
      "[0.75862069]\n",
      "[0.95402299]\n",
      "[0.37931034]\n",
      "[0.93103448]\n",
      "[0.8045977]\n",
      "[0.66666667]\n",
      "[0.18390805]\n",
      "[0.26436782]\n",
      "[0.18390805]\n",
      "[0.68965517]\n",
      "[0.4137931]\n",
      "[0.35632184]\n",
      "[0.77011494]\n",
      "[0.74712644]\n",
      "[0.70114943]\n",
      "[0.45977011]\n",
      "[0.82758621]\n",
      "[0.73563218]\n",
      "[0.29885057]\n",
      "[0.71264368]\n",
      "[0.45977011]\n",
      "[1.]\n",
      "[0.91954023]\n",
      "[0.97701149]\n",
      "[1.]\n",
      "[0.28735632]\n",
      "[0.01149425]\n",
      "[0.36781609]\n",
      "[0.55172414]\n",
      "[0.6091954]\n",
      "[0.83908046]\n",
      "[0.2183908]\n",
      "[0.98850575]\n",
      "[0.35632184]\n",
      "[0.83908046]\n",
      "[0.36781609]\n",
      "[0.89655172]\n",
      "[0.34482759]\n",
      "[0.86206897]\n",
      "[0.02298851]\n",
      "[0.96551724]\n",
      "[0.68965517]\n",
      "[0.42528736]\n",
      "[0.82758621]\n",
      "[0.6091954]\n",
      "[0.82758621]\n",
      "[0.65517241]\n",
      "[0.1954023]\n",
      "[0.5862069]\n",
      "[0.48275862]\n",
      "[0.08045977]\n",
      "[0.33333333]\n",
      "[0.1954023]\n",
      "[0.18390805]\n",
      "[0.59770115]\n",
      "[0.04597701]\n",
      "[0.14942529]\n",
      "[0.26436782]\n",
      "[0.12643678]\n",
      "[0.7816092]\n",
      "[0.72413793]\n",
      "[0.49425287]\n",
      "[0.77011494]\n",
      "[0.68965517]\n",
      "[1.]\n",
      "[0.24137931]\n",
      "[0.52873563]\n",
      "[0.37931034]\n",
      "[0.59770115]\n",
      "[0.98850575]\n",
      "[0.62068966]\n",
      "[0.64367816]\n",
      "[0.93103448]\n",
      "[0.24137931]\n",
      "[0.74712644]\n",
      "[0.88505747]\n",
      "[0.43678161]\n",
      "[0.91954023]\n",
      "[0.13793103]\n",
      "[0.74712644]\n",
      "[0.03448276]\n",
      "[0.72413793]\n",
      "[0.77011494]\n",
      "[0.35632184]\n",
      "[0.83908046]\n",
      "[0.59770115]\n",
      "[0.82758621]\n",
      "[0.62068966]\n",
      "[0.56321839]\n",
      "[0.73563218]\n",
      "[0.85057471]\n",
      "[0.86206897]\n",
      "[0.2183908]\n",
      "[0.96551724]\n",
      "[0.75862069]\n",
      "[0.63218391]\n",
      "[0.93103448]\n",
      "[0.70114943]\n",
      "[0.55172414]\n",
      "[0.59770115]\n",
      "[0.16091954]\n",
      "[0.10344828]\n",
      "[0.52873563]\n",
      "[0.94252874]\n",
      "[0.87356322]\n",
      "[0.01149425]\n",
      "[0.64367816]\n",
      "[0.65517241]\n",
      "[0.1954023]\n",
      "[0.26436782]\n",
      "[1.]\n",
      "[0.72413793]\n",
      "[0.98850575]\n",
      "[0.03448276]\n",
      "[0.66666667]\n",
      "[0.4137931]\n",
      "[0.02298851]\n",
      "[0.29885057]\n",
      "[0.97701149]\n",
      "[0.86206897]\n",
      "[0.05747126]\n",
      "[0.64367816]\n",
      "[0.13793103]\n",
      "[0.64367816]\n",
      "[0.09195402]\n",
      "[0.47126437]\n",
      "[0.77011494]\n",
      "[0.75862069]\n",
      "[0.03448276]\n",
      "[0.93103448]\n",
      "[0.86206897]\n",
      "[0.57471264]\n",
      "[0.57471264]\n",
      "[0.75862069]\n",
      "[0.87356322]\n",
      "[0.1954023]\n",
      "[0.43678161]\n",
      "[0.56321839]\n",
      "[0.82758621]\n",
      "[0.91954023]\n",
      "[0.63218391]\n",
      "[0.93103448]\n",
      "[0.45977011]\n",
      "[0.03448276]\n",
      "[0.32183908]\n",
      "[0.32183908]\n",
      "[0.91954023]\n",
      "[0.86206897]\n",
      "[0.49425287]\n",
      "[0.33333333]\n",
      "[0.22988506]\n",
      "[0.83908046]\n",
      "[0.5862069]\n",
      "[0.16091954]\n",
      "[0.95402299]\n",
      "[0.47126437]\n",
      "[0.94252874]\n",
      "[0.98850575]\n",
      "[0.62068966]\n",
      "[0.85057471]\n",
      "[0.28735632]\n",
      "[0.18390805]\n",
      "[0.10344828]\n",
      "[0.90804598]\n",
      "[0.]\n",
      "[0.90804598]\n",
      "[0.44827586]\n",
      "[0.85057471]\n",
      "[0.85057471]\n",
      "[0.36781609]\n",
      "[0.5862069]\n",
      "[0.31034483]\n",
      "[0.62068966]\n",
      "[0.77011494]\n",
      "[0.17241379]\n",
      "[0.57471264]\n",
      "[0.51724138]\n",
      "[0.87356322]\n",
      "[0.13793103]\n",
      "[0.51724138]\n",
      "[0.04597701]\n",
      "[0.44827586]\n",
      "[0.35632184]\n",
      "[0.47126437]\n",
      "[0.26436782]\n",
      "[0.04597701]\n",
      "[0.97701149]\n",
      "[0.82758621]\n",
      "[0.79310345]\n",
      "[0.12643678]\n",
      "[0.27586207]\n",
      "[0.17241379]\n",
      "[0.51724138]\n",
      "[0.81609195]\n",
      "[0.90804598]\n",
      "[0.81609195]\n",
      "[0.90804598]\n",
      "[0.33333333]\n",
      "[0.64367816]\n",
      "[0.02298851]\n",
      "[0.90804598]\n",
      "[0.34482759]\n",
      "[0.44827586]\n",
      "[0.96551724]\n",
      "[0.57471264]\n",
      "[0.49425287]\n",
      "[0.03448276]\n",
      "[0.17241379]\n",
      "[0.59770115]\n",
      "[0.40229885]\n",
      "[0.65517241]\n",
      "[0.25287356]\n",
      "[0.96551724]\n",
      "[0.83908046]\n",
      "[0.94252874]\n",
      "[0.77011494]\n",
      "[0.11494253]\n",
      "[0.04597701]\n",
      "[0.8045977]\n",
      "[0.05747126]\n",
      "[0.82758621]\n",
      "[1.]\n",
      "[0.74712644]\n",
      "[0.29885057]\n",
      "[0.73563218]\n",
      "[0.70114943]\n",
      "[0.10344828]\n",
      "[0.91954023]\n",
      "[1.]\n",
      "[0.82758621]\n",
      "[0.01149425]\n",
      "[0.44827586]\n",
      "[0.65517241]\n",
      "[0.94252874]\n",
      "[0.62068966]\n",
      "[0.89655172]\n",
      "[0.12643678]\n",
      "[0.98850575]\n",
      "[0.98850575]\n",
      "[1.]\n",
      "[0.27586207]\n",
      "[0.97701149]\n",
      "[0.89655172]\n",
      "[0.16091954]\n",
      "[0.97701149]\n",
      "[0.75862069]\n",
      "[0.93103448]\n",
      "[0.59770115]\n",
      "[0.86206897]\n",
      "[0.06896552]\n",
      "[0.73563218]\n",
      "[0.51724138]\n",
      "[0.31034483]\n",
      "[0.13793103]\n",
      "[0.6091954]\n",
      "[0.26436782]\n",
      "[0.02298851]\n",
      "[0.63218391]\n",
      "[0.6091954]\n",
      "[0.01149425]\n",
      "[0.59770115]\n",
      "[0.01149425]\n",
      "[0.7816092]\n",
      "[0.29885057]\n",
      "[0.17241379]\n",
      "[0.20689655]\n",
      "[0.59770115]\n",
      "[0.63218391]\n",
      "[0.34482759]\n",
      "[0.33333333]\n",
      "[0.70114943]\n",
      "[0.91954023]\n",
      "[0.34482759]\n",
      "[0.18390805]\n",
      "[0.90804598]\n",
      "[0.97701149]\n",
      "[0.26436782]\n",
      "[0.96551724]\n",
      "[0.25287356]\n",
      "[0.47126437]\n",
      "[0.73563218]\n",
      "[0.64367816]\n",
      "[0.82758621]\n",
      "[0.8045977]\n",
      "[0.67816092]\n",
      "[0.47126437]\n",
      "[0.95402299]\n",
      "[0.98850575]\n",
      "[0.74712644]\n",
      "[0.31034483]\n",
      "[0.90804598]\n",
      "[0.97701149]\n",
      "[0.34482759]\n",
      "[0.82758621]\n",
      "[0.26436782]\n",
      "[0.90804598]\n",
      "[0.68965517]\n",
      "[0.48275862]\n",
      "[0.56321839]\n",
      "[0.2183908]\n",
      "[0.91954023]\n",
      "[0.09195402]\n",
      "[0.71264368]\n",
      "[0.52873563]\n",
      "[0.65517241]\n",
      "[0.8045977]\n",
      "[0.94252874]\n",
      "[0.29885057]\n",
      "[0.67816092]\n",
      "[0.85057471]\n",
      "[0.3908046]\n",
      "[1.]\n",
      "[0.65517241]\n",
      "[0.54022989]\n",
      "[0.36781609]\n",
      "[0.42528736]\n",
      "[0.95402299]\n",
      "[0.]\n",
      "[0.49425287]\n",
      "[0.65517241]\n",
      "[0.86206897]\n",
      "[0.01149425]\n",
      "[0.90804598]\n",
      "[0.1954023]\n",
      "[0.90804598]\n",
      "[0.35632184]\n",
      "[0.95402299]\n",
      "[0.24137931]\n",
      "[0.24137931]\n",
      "[0.68965517]\n",
      "[0.45977011]\n",
      "[0.54022989]\n",
      "[0.67816092]\n",
      "[0.55172414]\n",
      "[0.25287356]\n",
      "[0.49425287]\n",
      "[0.62068966]\n",
      "[0.64367816]\n",
      "[0.72413793]\n",
      "[0.75862069]\n",
      "[0.10344828]\n",
      "[0.09195402]\n",
      "[0.25287356]\n",
      "[0.98850575]\n",
      "[0.7816092]\n",
      "[0.34482759]\n",
      "[0.40229885]\n",
      "[0.4137931]\n",
      "[0.48275862]\n",
      "[0.2183908]\n",
      "[0.26436782]\n",
      "[0.83908046]\n",
      "[0.06896552]\n",
      "[0.93103448]\n",
      "[0.77011494]\n",
      "[0.74712644]\n",
      "[0.54022989]\n",
      "[0.67816092]\n",
      "[0.86206897]\n",
      "[0.68965517]\n",
      "[0.27586207]\n",
      "[0.85057471]\n",
      "[0.33333333]\n",
      "[0.55172414]\n",
      "[0.02298851]\n",
      "[0.44827586]\n",
      "[0.17241379]\n",
      "[1.]\n",
      "[0.94252874]\n",
      "[0.40229885]\n",
      "[0.09195402]\n",
      "[0.89655172]\n",
      "[0.35632184]\n",
      "[0.52873563]\n",
      "[0.03448276]\n",
      "[0.3908046]\n",
      "[0.04597701]\n",
      "[0.57471264]\n",
      "[1.]\n",
      "[0.11494253]\n",
      "[0.94252874]\n",
      "[0.28735632]\n",
      "[0.49425287]\n",
      "[0.81609195]\n",
      "[0.86206897]\n",
      "[0.50574713]\n",
      "[0.5862069]\n",
      "[0.89655172]\n",
      "[0.95402299]\n",
      "[0.13793103]\n",
      "[0.52873563]\n",
      "[0.11494253]\n",
      "[0.95402299]\n",
      "[0.50574713]\n",
      "[0.54022989]\n",
      "[0.11494253]\n",
      "[0.88505747]\n",
      "[0.52873563]\n",
      "[0.71264368]\n",
      "[0.98850575]\n",
      "[0.14942529]\n",
      "[0.09195402]\n",
      "[0.05747126]\n",
      "[0.73563218]\n",
      "[0.01149425]\n",
      "[0.3908046]\n",
      "[0.11494253]\n",
      "[0.79310345]\n",
      "[0.70114943]\n",
      "[0.45977011]\n",
      "[0.04597701]\n",
      "[0.73563218]\n",
      "[0.33333333]\n",
      "[0.2183908]\n",
      "[0.91954023]\n",
      "[0.79310345]\n",
      "[0.13793103]\n",
      "[0.83908046]\n",
      "[0.50574713]\n",
      "[0.74712644]\n",
      "[0.43678161]\n",
      "[0.67816092]\n",
      "[0.34482759]\n",
      "[0.17241379]\n",
      "[0.17241379]\n",
      "[0.88505747]\n",
      "[0.18390805]\n",
      "[0.7816092]\n",
      "[0.48275862]\n",
      "[0.44827586]\n",
      "[0.95402299]\n",
      "[0.87356322]\n",
      "[0.73563218]\n",
      "[0.36781609]\n",
      "[0.83908046]\n",
      "[0.7816092]\n",
      "[0.66666667]\n",
      "[0.31034483]\n",
      "[0.88505747]\n",
      "[0.27586207]\n",
      "[1.]\n",
      "[0.2183908]\n",
      "[0.20689655]\n",
      "[0.82758621]\n",
      "[0.54022989]\n",
      "[1.]\n",
      "[0.18390805]\n",
      "[0.73563218]\n",
      "[0.62068966]\n",
      "[0.12643678]\n",
      "[0.31034483]\n",
      "[0.64367816]\n",
      "[0.32183908]\n",
      "[0.44827586]\n",
      "[0.81609195]\n",
      "[0.7816092]\n",
      "[0.83908046]\n",
      "[0.6091954]\n",
      "[0.2183908]\n",
      "[1.]\n",
      "[0.01149425]\n",
      "[0.5862069]\n",
      "[0.66666667]\n",
      "[0.49425287]\n",
      "[0.97701149]\n",
      "[0.79310345]\n",
      "[0.87356322]\n",
      "[0.50574713]\n",
      "[0.82758621]\n",
      "[0.65517241]\n",
      "[0.68965517]\n",
      "[0.24137931]\n",
      "[0.95402299]\n",
      "[0.65517241]\n",
      "[0.55172414]\n",
      "[0.12643678]\n",
      "[0.94252874]\n",
      "[0.32183908]\n",
      "[0.72413793]\n",
      "[0.33333333]\n",
      "[0.74712644]\n",
      "[0.09195402]\n",
      "[0.81609195]\n",
      "[0.50574713]\n",
      "[1.]\n",
      "[0.04597701]\n",
      "[0.68965517]\n",
      "[0.73563218]\n",
      "[0.94252874]\n",
      "[1.]\n",
      "[0.57471264]\n",
      "[0.90804598]\n",
      "[0.43678161]\n",
      "[0.34482759]\n",
      "[0.49425287]\n",
      "[0.1954023]\n",
      "[0.51724138]\n",
      "[0.66666667]\n",
      "[0.72413793]\n",
      "[0.89655172]\n",
      "[0.68965517]\n",
      "[0.7816092]\n",
      "[0.89655172]\n",
      "[0.89655172]\n",
      "[0.59770115]\n",
      "[0.59770115]\n",
      "[0.62068966]\n",
      "[0.24137931]\n",
      "[0.28735632]\n",
      "[1.]\n",
      "[0.73563218]\n",
      "[0.33333333]\n",
      "[0.97701149]\n",
      "[0.63218391]\n",
      "[0.04597701]\n",
      "[0.59770115]\n",
      "[0.6091954]\n",
      "[0.86206897]\n",
      "[0.01149425]\n",
      "[0.68965517]\n",
      "[0.40229885]\n",
      "[0.95402299]\n",
      "[0.68965517]\n",
      "[0.20689655]\n",
      "[0.63218391]\n",
      "[0.32183908]\n",
      "[0.10344828]\n",
      "[0.82758621]\n",
      "[0.20689655]\n",
      "[0.57471264]\n",
      "[0.66666667]\n",
      "[0.90804598]\n",
      "[0.73563218]\n",
      "[0.8045977]\n",
      "[0.79310345]\n",
      "[0.2183908]\n",
      "[0.86206897]\n",
      "[0.77011494]\n",
      "[0.98850575]\n",
      "[0.65517241]\n",
      "[0.13793103]\n",
      "[0.95402299]\n",
      "[0.40229885]\n",
      "[0.55172414]\n",
      "[0.89655172]\n",
      "[0.6091954]\n",
      "[0.43678161]\n",
      "[0.1954023]\n",
      "[0.09195402]\n",
      "[0.81609195]\n",
      "[0.18390805]\n",
      "[0.81609195]\n",
      "[0.68965517]\n",
      "[0.8045977]\n",
      "[0.13793103]\n",
      "[0.75862069]\n",
      "[0.96551724]\n",
      "[0.1954023]\n",
      "[0.59770115]\n",
      "[0.85057471]\n",
      "[0.08045977]\n",
      "[0.95402299]\n",
      "[0.71264368]\n",
      "[0.95402299]\n",
      "[0.25287356]\n",
      "[0.97701149]\n",
      "[0.25287356]\n",
      "[0.51724138]\n",
      "[0.09195402]\n",
      "[1.]\n",
      "[0.8045977]\n",
      "[0.91954023]\n",
      "[0.12643678]\n",
      "[0.62068966]\n",
      "[0.66666667]\n",
      "[0.32183908]\n",
      "[0.01149425]\n",
      "[0.27586207]\n",
      "[0.57471264]\n",
      "[0.7816092]\n",
      "[0.96551724]\n",
      "[0.33333333]\n",
      "[0.54022989]\n",
      "[0.64367816]\n",
      "[0.01149425]\n",
      "[0.28735632]\n",
      "[0.79310345]\n",
      "[0.72413793]\n",
      "[0.74712644]\n",
      "[0.5862069]\n",
      "[0.85057471]\n",
      "[0.74712644]\n",
      "[0.83908046]\n",
      "[0.65517241]\n",
      "[0.33333333]\n",
      "[0.81609195]\n",
      "[0.98850575]\n",
      "[0.26436782]\n",
      "[0.37931034]\n",
      "[0.62068966]\n",
      "[0.48275862]\n",
      "[0.94252874]\n",
      "[0.42528736]\n",
      "[0.7816092]\n",
      "[0.79310345]\n",
      "[0.50574713]\n",
      "[0.79310345]\n",
      "[0.08045977]\n",
      "[0.68965517]\n",
      "[0.83908046]\n",
      "[0.72413793]\n",
      "[0.67816092]\n",
      "[0.22988506]\n",
      "[0.65517241]\n",
      "[0.10344828]\n",
      "[0.59770115]\n",
      "[0.68965517]\n",
      "[0.93103448]\n",
      "[0.29885057]\n",
      "[0.75862069]\n",
      "[0.7816092]\n",
      "[0.2183908]\n",
      "[0.]\n",
      "[0.56321839]\n",
      "[0.01149425]\n",
      "[0.90804598]\n",
      "[0.77011494]\n",
      "[0.86206897]\n",
      "[0.64367816]\n",
      "[0.14942529]\n",
      "[0.6091954]\n",
      "[0.43678161]\n",
      "[0.2183908]\n",
      "[0.37931034]\n",
      "[0.31034483]\n",
      "[0.3908046]\n",
      "[0.72413793]\n",
      "[0.54022989]\n",
      "[0.42528736]\n",
      "[0.87356322]\n",
      "[0.88505747]\n",
      "[0.14942529]\n",
      "[0.70114943]\n",
      "[0.56321839]\n",
      "[0.27586207]\n",
      "[0.67816092]\n",
      "[0.82758621]\n",
      "[0.96551724]\n",
      "[0.36781609]\n",
      "[0.45977011]\n",
      "[0.70114943]\n",
      "[0.47126437]\n",
      "[0.95402299]\n",
      "[0.83908046]\n",
      "[0.87356322]\n",
      "[0.02298851]\n",
      "[0.79310345]\n",
      "[0.6091954]\n",
      "[0.52873563]\n",
      "[0.28735632]\n",
      "[0.81609195]\n",
      "[0.32183908]\n",
      "[0.82758621]\n",
      "[0.04597701]\n",
      "[0.86206897]\n",
      "[0.13793103]\n",
      "[0.3908046]\n",
      "[0.11494253]\n",
      "[0.95402299]\n",
      "[0.09195402]\n",
      "[0.1954023]\n",
      "[0.83908046]\n",
      "[0.02298851]\n",
      "[0.50574713]\n",
      "[0.73563218]\n",
      "[0.3908046]\n",
      "[0.67816092]\n",
      "[0.25287356]\n",
      "[0.2183908]\n",
      "[0.7816092]\n",
      "[0.72413793]\n",
      "[0.94252874]\n",
      "[0.31034483]\n",
      "[0.95402299]\n",
      "[0.43678161]\n",
      "[0.18390805]\n",
      "[0.98850575]\n",
      "[0.47126437]\n",
      "[0.24137931]\n",
      "[0.93103448]\n",
      "[0.35632184]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13793103]\n",
      "[0.34482759]\n",
      "[0.93103448]\n",
      "[0.50574713]\n",
      "[0.82758621]\n",
      "[0.88505747]\n",
      "[0.42528736]\n",
      "[0.65517241]\n",
      "[0.17241379]\n",
      "[0.8045977]\n",
      "[0.27586207]\n",
      "[0.31034483]\n",
      "[0.6091954]\n",
      "[0.10344828]\n",
      "[0.17241379]\n",
      "[0.65517241]\n",
      "[0.4137931]\n",
      "[0.98850575]\n",
      "[0.57471264]\n"
     ]
    }
   ],
   "source": [
    "for i in scaled_train_samples:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Creating a simple artifical neural network using a Sequential model from tf.keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Build a Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(units = 16, input_shape = (1,), activation = \"relu\"),\n",
    "    Dense(units  = 32, activation = \"relu\"),\n",
    "    Dense(units = 2, activation = \"softmax\")\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* model is an instance of a Sequential object. \n",
    "* A tf.keras.Sequential model is a linear stack of layers. It accepts a list, and each element in the list should be a layer.\n",
    "\n",
    "\n",
    "**First Hidden Layer**\n",
    "\n",
    "* The first layer is a Dense layer. This type of layer is our standard fully-connected or densely-connected neural network layer. The first required parameter that the Dense layer expects is the number of neurons or units the layer has, and above arbitrarily setting this to 16.\n",
    "\n",
    "* Additionally, the model needs to know the shape of the input data. For this reason, the shape of the input data in the first hidden layer in the model (and only this layer)is being specified. The parameter called input_shape is how we specify this.\n",
    "\n",
    "* think of the way we specify the input_shape here as acting as an implicit input layer. The input layer of a neural network is the underlying raw data itself, therefore we don't create an explicit input layer. This first Dense layer that we're working with now is actually the first hidden layer.\n",
    "\n",
    "* Lastly, an optional parameter that weâ€™ll set for the Dense layer is the activation function to use after this layer. Weâ€™ll use the popular choice of relu. Note, if you donâ€™t explicitly set an activation function, then Keras will use the linear activation function.\n",
    "\n",
    "**Second Hidden Layer**\n",
    "\n",
    "* layer will also be a Dense layer, and this one will have 32 nodes. The choice of how many neurons this node has is also arbitrary, as the idea is to create a simple model,\n",
    "\n",
    "* This Dense layer will also use relu as its activation function.\n",
    "\n",
    "**Output Layer**\n",
    "\n",
    "* This layer is also a Dense layer, and it will have 2 neurons. This is because we have two possible outputs: either a patient experienced side effects, or the patient did not experience side effects.\n",
    "\n",
    "* This time, the activation function weâ€™ll use is softmax, which will give us a probability distribution among the possible outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Training the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Compiling the model\n",
    "\n",
    "The first to get the model ready for training is call the compile() function on it.This function configures the model for training and expects a number of parameters. \n",
    "\n",
    "\n",
    "* First, we specify the optimizer Adam. Adam accepts an optional parameter learning_rate, which weâ€™ll set to 0.0001.Adam optimization is a stochastic gradient descent (SGD) method,\n",
    "\n",
    "* The next parameter we specify is loss. Weâ€™ll be using sparse_categorical_crossentropy, given that our labels are in integer format.\n",
    "\n",
    "* the last parameter we specify in compile() is metrics. This parameter expects a list of metrics that weâ€™d like to be evaluated by the model during training and testing. Weâ€™ll set this to a list that contains the string â€˜accuracyâ€™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Training The Model\n",
    "\n",
    "the model is compiled, we can train it using the fit() function.\n",
    "\n",
    "\n",
    "* The first item that we pass in to the fit() function is the training set x.We created the training set and gave it the name scaled_train_samples.\n",
    "\n",
    "* The next parameter that we set is the labels for the training set y, which we previously gave the name train_labels.\n",
    "\n",
    "* We then specify the batch_size.\n",
    "\n",
    "* Next, we specify how many epochs we want to run. We set this to 30. Note that an epoch is a single pass of all the data to the network.\n",
    "\n",
    "*  verbose=2. This just specifies how much output to the console we want to see during each epoch of training. The verbosity levels range from 0 to 2, so weâ€™re getting the most verbose output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "210/210 - 0s - loss: 0.6710 - accuracy: 0.5657\n",
      "Epoch 2/30\n",
      "210/210 - 0s - loss: 0.6419 - accuracy: 0.6414\n",
      "Epoch 3/30\n",
      "210/210 - 0s - loss: 0.6147 - accuracy: 0.6781\n",
      "Epoch 4/30\n",
      "210/210 - 0s - loss: 0.5871 - accuracy: 0.7219\n",
      "Epoch 5/30\n",
      "210/210 - 0s - loss: 0.5609 - accuracy: 0.7552\n",
      "Epoch 6/30\n",
      "210/210 - 0s - loss: 0.5333 - accuracy: 0.7829\n",
      "Epoch 7/30\n",
      "210/210 - 0s - loss: 0.5007 - accuracy: 0.8119\n",
      "Epoch 8/30\n",
      "210/210 - 0s - loss: 0.4679 - accuracy: 0.8457\n",
      "Epoch 9/30\n",
      "210/210 - 0s - loss: 0.4382 - accuracy: 0.8619\n",
      "Epoch 10/30\n",
      "210/210 - 0s - loss: 0.4111 - accuracy: 0.8819\n",
      "Epoch 11/30\n",
      "210/210 - 0s - loss: 0.3869 - accuracy: 0.8943\n",
      "Epoch 12/30\n",
      "210/210 - 0s - loss: 0.3659 - accuracy: 0.9062\n",
      "Epoch 13/30\n",
      "210/210 - 0s - loss: 0.3475 - accuracy: 0.9086\n",
      "Epoch 14/30\n",
      "210/210 - 0s - loss: 0.3323 - accuracy: 0.9190\n",
      "Epoch 15/30\n",
      "210/210 - 0s - loss: 0.3202 - accuracy: 0.9200\n",
      "Epoch 16/30\n",
      "210/210 - 0s - loss: 0.3102 - accuracy: 0.9233\n",
      "Epoch 17/30\n",
      "210/210 - 0s - loss: 0.3021 - accuracy: 0.9262\n",
      "Epoch 18/30\n",
      "210/210 - 0s - loss: 0.2955 - accuracy: 0.9310\n",
      "Epoch 19/30\n",
      "210/210 - 0s - loss: 0.2905 - accuracy: 0.9310\n",
      "Epoch 20/30\n",
      "210/210 - 0s - loss: 0.2855 - accuracy: 0.9329\n",
      "Epoch 21/30\n",
      "210/210 - 0s - loss: 0.2818 - accuracy: 0.9390\n",
      "Epoch 22/30\n",
      "210/210 - 0s - loss: 0.2786 - accuracy: 0.9376\n",
      "Epoch 23/30\n",
      "210/210 - 0s - loss: 0.2757 - accuracy: 0.9352\n",
      "Epoch 24/30\n",
      "210/210 - 0s - loss: 0.2731 - accuracy: 0.9400\n",
      "Epoch 25/30\n",
      "210/210 - 0s - loss: 0.2709 - accuracy: 0.9367\n",
      "Epoch 26/30\n",
      "210/210 - 0s - loss: 0.2689 - accuracy: 0.9390\n",
      "Epoch 27/30\n",
      "210/210 - 0s - loss: 0.2670 - accuracy: 0.9386\n",
      "Epoch 28/30\n",
      "210/210 - 0s - loss: 0.2653 - accuracy: 0.9424\n",
      "Epoch 29/30\n",
      "210/210 - 0s - loss: 0.2637 - accuracy: 0.9376\n",
      "Epoch 30/30\n",
      "210/210 - 0s - loss: 0.2623 - accuracy: 0.9429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa40c2521d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_train_samples, y=train_labels, batch_size=10, epochs=30, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Building A Validation set With Tensorflow's Keras API\n",
    "\n",
    "### What is A Validation Set?\n",
    "\n",
    "* Before training begins, we can choose to remove a portion of the training set and place it in a validation set. Then, during training, the model will train only on the training set, and it will validate by evaluating the data in the validation set.\n",
    "\n",
    "* Essentially, the model is learning the features of the data in the training set, taking what it's learned from this data, and then predicting on the validation set. \n",
    "\n",
    "* This allows us to see how well the model is generalizing on data it wasnâ€™t trained on because, recall, the validation data should not be part of the training data.\n",
    "\n",
    "* This also helps us see whether or not the model is overfitting. Overfitting occurs when the model only learns the specifics of the training data and is unable to generalize well on data that it wasnâ€™t trained on.\n",
    "\n",
    "\n",
    "### Creating a Validation Set.\n",
    "\n",
    "There are two ways to create a validation set to use with a tf.keras.Sequential model.\n",
    "\n",
    "**1.Manually Create Validation Set**\n",
    "\n",
    "The first way is to create a data structure to hold a validation set, and place data directly in that structure in the same nature we did for the training set.\n",
    "\n",
    "This data structure should be a tuple valid_set = (x_val, y_val) of Numpy arrays or tensors, where x_val is a numpy array or tensor containing validation samples, and y_val is a numpy array or tensor containing validation labels.\n",
    "\n",
    "When we call model.fit(), we would pass in the validation set in addition to the training set. We pass the validation set by specifying the validation_data parameter.\n",
    "\n",
    "\n",
    "   **model.fit(\n",
    "      x=scaled_train_samples\n",
    "    , y=train_labels\n",
    "    , validation_data=valid_set\n",
    "    , batch_size=10\n",
    "    , epochs=30\n",
    "    , verbose=2\n",
    "    )**\n",
    "    \n",
    "    \n",
    "**2.Create Validation Set With Keras**\n",
    "\n",
    "There is another way to create a validation set, and it saves a step!\n",
    "\n",
    "If we donâ€™t already have a specified validation set created, then when we call model.fit(), we can set a value for the validation_split parameter. It expects a fractional number between 0 and 1. Suppose that we set this parameter to 0.1.\n",
    "\n",
    "**model.fit(\n",
    "      x=scaled_train_samples\n",
    "    , y=train_labels\n",
    "    , validation_split=0.1\n",
    "    , batch_size=10\n",
    "    , epochs=30\n",
    "    , verbose=2\n",
    ")**\n",
    "\n",
    "\n",
    "With this parameter specified, Keras will split apart a fraction (10% in this example) of the training data to be used as validation data. The model will set apart this fraction of the training data, will not train on it, and will evaluate the loss and any model metrics on this data at the end of each epoch.\n",
    "\n",
    "**NOTE-\n",
    "Note that the fit() function shuffles the data before each epoch by default. When specifying the validation_split parameter, however, the validation data is selected from the last samples in the x and y data before shuffling.\n",
    "Therefore, in the case we're using validation_split in this way to create our validation data, we need to be sure that our data has been shuffled ahead of time, like we previously did in an earlier episode.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "189/189 - 0s - loss: 0.2639 - accuracy: 0.9444 - val_loss: 0.2355 - val_accuracy: 0.9571\n",
      "Epoch 2/30\n",
      "189/189 - 0s - loss: 0.2626 - accuracy: 0.9418 - val_loss: 0.2350 - val_accuracy: 0.9571\n",
      "Epoch 3/30\n",
      "189/189 - 0s - loss: 0.2614 - accuracy: 0.9450 - val_loss: 0.2349 - val_accuracy: 0.9571\n",
      "Epoch 4/30\n",
      "189/189 - 0s - loss: 0.2605 - accuracy: 0.9439 - val_loss: 0.2339 - val_accuracy: 0.9571\n",
      "Epoch 5/30\n",
      "189/189 - 0s - loss: 0.2595 - accuracy: 0.9429 - val_loss: 0.2357 - val_accuracy: 0.9571\n",
      "Epoch 6/30\n",
      "189/189 - 0s - loss: 0.2588 - accuracy: 0.9429 - val_loss: 0.2334 - val_accuracy: 0.9571\n",
      "Epoch 7/30\n",
      "189/189 - 0s - loss: 0.2578 - accuracy: 0.9418 - val_loss: 0.2331 - val_accuracy: 0.9571\n",
      "Epoch 8/30\n",
      "189/189 - 0s - loss: 0.2571 - accuracy: 0.9418 - val_loss: 0.2352 - val_accuracy: 0.9619\n",
      "Epoch 9/30\n",
      "189/189 - 0s - loss: 0.2564 - accuracy: 0.9450 - val_loss: 0.2334 - val_accuracy: 0.9571\n",
      "Epoch 10/30\n",
      "189/189 - 0s - loss: 0.2558 - accuracy: 0.9444 - val_loss: 0.2327 - val_accuracy: 0.9571\n",
      "Epoch 11/30\n",
      "189/189 - 0s - loss: 0.2553 - accuracy: 0.9444 - val_loss: 0.2318 - val_accuracy: 0.9571\n",
      "Epoch 12/30\n",
      "189/189 - 0s - loss: 0.2546 - accuracy: 0.9434 - val_loss: 0.2326 - val_accuracy: 0.9571\n",
      "Epoch 13/30\n",
      "189/189 - 0s - loss: 0.2541 - accuracy: 0.9455 - val_loss: 0.2384 - val_accuracy: 0.9619\n",
      "Epoch 14/30\n",
      "189/189 - 0s - loss: 0.2535 - accuracy: 0.9508 - val_loss: 0.2313 - val_accuracy: 0.9571\n",
      "Epoch 15/30\n",
      "189/189 - 0s - loss: 0.2531 - accuracy: 0.9429 - val_loss: 0.2358 - val_accuracy: 0.9619\n",
      "Epoch 16/30\n",
      "189/189 - 0s - loss: 0.2528 - accuracy: 0.9508 - val_loss: 0.2313 - val_accuracy: 0.9571\n",
      "Epoch 17/30\n",
      "189/189 - 0s - loss: 0.2523 - accuracy: 0.9471 - val_loss: 0.2322 - val_accuracy: 0.9619\n",
      "Epoch 18/30\n",
      "189/189 - 0s - loss: 0.2519 - accuracy: 0.9455 - val_loss: 0.2309 - val_accuracy: 0.9619\n",
      "Epoch 19/30\n",
      "189/189 - 0s - loss: 0.2515 - accuracy: 0.9487 - val_loss: 0.2306 - val_accuracy: 0.9619\n",
      "Epoch 20/30\n",
      "189/189 - 0s - loss: 0.2512 - accuracy: 0.9476 - val_loss: 0.2312 - val_accuracy: 0.9619\n",
      "Epoch 21/30\n",
      "189/189 - 0s - loss: 0.2508 - accuracy: 0.9487 - val_loss: 0.2333 - val_accuracy: 0.9619\n",
      "Epoch 22/30\n",
      "189/189 - 0s - loss: 0.2505 - accuracy: 0.9519 - val_loss: 0.2331 - val_accuracy: 0.9619\n",
      "Epoch 23/30\n",
      "189/189 - 0s - loss: 0.2503 - accuracy: 0.9503 - val_loss: 0.2299 - val_accuracy: 0.9619\n",
      "Epoch 24/30\n",
      "189/189 - 0s - loss: 0.2501 - accuracy: 0.9481 - val_loss: 0.2293 - val_accuracy: 0.9619\n",
      "Epoch 25/30\n",
      "189/189 - 0s - loss: 0.2498 - accuracy: 0.9487 - val_loss: 0.2310 - val_accuracy: 0.9619\n",
      "Epoch 26/30\n",
      "189/189 - 0s - loss: 0.2496 - accuracy: 0.9481 - val_loss: 0.2300 - val_accuracy: 0.9619\n",
      "Epoch 27/30\n",
      "189/189 - 0s - loss: 0.2493 - accuracy: 0.9481 - val_loss: 0.2291 - val_accuracy: 0.9619\n",
      "Epoch 28/30\n",
      "189/189 - 0s - loss: 0.2489 - accuracy: 0.9508 - val_loss: 0.2293 - val_accuracy: 0.9619\n",
      "Epoch 29/30\n",
      "189/189 - 0s - loss: 0.2488 - accuracy: 0.9471 - val_loss: 0.2296 - val_accuracy: 0.9619\n",
      "Epoch 30/30\n",
      "189/189 - 0s - loss: 0.2485 - accuracy: 0.9476 - val_loss: 0.2289 - val_accuracy: 0.9619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa3e836cb90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "      x=scaled_train_samples\n",
    "    , y=train_labels\n",
    "    , validation_split=0.1\n",
    "    , batch_size=10\n",
    "    , epochs=30\n",
    "    , verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Neural Network Prediction on Test Data\n",
    "\n",
    "\n",
    "### What Is Inference?\n",
    "\n",
    "* Now suppose that later we want to take this model and use it to predict on other images of cats and dogs from a different data set. The hope is that, even though our model wasnâ€™t exposed to these particular dog and cat images during training, it will still be able to accurately make predictions for them based on what itâ€™s learned from the cat and dog data set from which it was trained.\n",
    "\n",
    "* We call this process inference, as the model is using its knowledge gained from training and using it to infer a prediction or result.\n",
    "\n",
    "* At this point, the model we've been working with has now been trained and validated. Given the results weâ€™ve seen from the validation data, it appears that this model should do well on predicting on a new test set.\n",
    "\n",
    "* Note that the test set is the set of data used specifically for inference after training has concluded. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Creating the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels =  []\n",
    "test_samples = []\n",
    "\n",
    "for i in range(10):\n",
    "    # The 5% of younger individuals who did experience side effects\n",
    "    random_younger = randint(13,64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(1)\n",
    "\n",
    "    # The 5% of older individuals who did not experience side effects\n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(0)\n",
    "\n",
    "for i in range(200):\n",
    "    # The 95% of younger individuals who did not experience side effects\n",
    "    random_younger = randint(13,64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(0)\n",
    "\n",
    "    # The 95% of older individuals who did experience side effects\n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.array(test_labels)\n",
    "test_samples = np.array(test_samples)\n",
    "test_labels, test_samples = shuffle(test_labels, test_samples)\n",
    "\n",
    "scaled_test_samples = scaler.fit_transform(test_samples.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Evaluating The Test Set\n",
    "\n",
    "* To get predictions from the model for the test set, we call model.predict()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(\n",
    "      x=scaled_test_samples\n",
    "    , batch_size=10\n",
    "    , verbose=0\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4073816 0.5926184]\n",
      "[0.22798389 0.7720161 ]\n",
      "[0.07920998 0.92079   ]\n",
      "[0.78835887 0.21164118]\n",
      "[0.97303694 0.02696309]\n",
      "[0.97439384 0.02560617]\n",
      "[0.08692199 0.91307795]\n",
      "[0.02040021 0.97959983]\n",
      "[0.9750371 0.0249629]\n",
      "[0.19294864 0.80705136]\n",
      "[0.0368383 0.9631617]\n",
      "[0.02252648 0.9774735 ]\n",
      "[0.93261105 0.06738893]\n",
      "[0.0542484 0.9457516]\n",
      "[0.94890416 0.05109582]\n",
      "[0.96077466 0.03922535]\n",
      "[0.96077466 0.03922535]\n",
      "[0.19294864 0.80705136]\n",
      "[0.8753112  0.12468877]\n",
      "[0.01847085 0.9815291 ]\n",
      "[0.0368383 0.9631617]\n",
      "[0.85037255 0.14962745]\n",
      "[0.94564503 0.05435494]\n",
      "[0.13643579 0.86356425]\n",
      "[0.9741759  0.02582416]\n",
      "[0.9755089  0.02449108]\n",
      "[0.4073816 0.5926184]\n",
      "[0.9662113  0.03378867]\n",
      "[0.04474302 0.95525694]\n",
      "[0.2672739  0.73272616]\n",
      "[0.51191396 0.48808601]\n",
      "[0.96758556 0.03241438]\n",
      "[0.975771   0.02422897]\n",
      "[0.08692199 0.91307795]\n",
      "[0.9377278 0.0622722]\n",
      "[0.06563438 0.9343656 ]\n",
      "[0.9698835  0.03011651]\n",
      "[0.8965987 0.1034013]\n",
      "[0.22798389 0.7720161 ]\n",
      "[0.08692199 0.91307795]\n",
      "[0.04927884 0.95072114]\n",
      "[0.10440863 0.8955913 ]\n",
      "[0.9737344  0.02626559]\n",
      "[0.975771   0.02422897]\n",
      "[0.10440863 0.8955913 ]\n",
      "[0.9247453  0.07525464]\n",
      "[0.973511   0.02648904]\n",
      "[0.5643653  0.43563464]\n",
      "[0.973511   0.02648904]\n",
      "[0.9135783  0.08642175]\n",
      "[0.07212819 0.9278718 ]\n",
      "[0.07920998 0.92079   ]\n",
      "[0.93261105 0.06738893]\n",
      "[0.9755089  0.02449108]\n",
      "[0.9519777  0.04802222]\n",
      "[0.9135783  0.08642175]\n",
      "[0.6154145  0.38458553]\n",
      "[0.01121179 0.9887882 ]\n",
      "[0.9247453  0.07525465]\n",
      "[0.9755966 0.0244034]\n",
      "[0.0136958 0.9863042]\n",
      "[0.0136958 0.9863042]\n",
      "[0.03028582 0.9697142 ]\n",
      "[0.96758556 0.03241438]\n",
      "[0.4073816 0.5926184]\n",
      "[0.973511   0.02648904]\n",
      "[0.9748244  0.02517555]\n",
      "[0.9748244  0.02517555]\n",
      "[0.9698835  0.03011651]\n",
      "[0.66404283 0.33595717]\n",
      "[0.13643579 0.86356425]\n",
      "[0.11426958 0.88573045]\n",
      "[0.02040021 0.97959983]\n",
      "[0.01847085 0.9815291 ]\n",
      "[0.22798389 0.7720161 ]\n",
      "[0.06563438 0.9343656 ]\n",
      "[0.01672084 0.9832791 ]\n",
      "[0.0368383 0.9631617]\n",
      "[0.04060684 0.9593932 ]\n",
      "[0.97461003 0.02538998]\n",
      "[0.0368383 0.9631617]\n",
      "[0.9626742  0.03732581]\n",
      "[0.97461003 0.02538998]\n",
      "[0.94890416 0.05109582]\n",
      "[0.0123925  0.98760754]\n",
      "[0.78835887 0.21164118]\n",
      "[0.01121179 0.9887882 ]\n",
      "[0.9751551  0.02484488]\n",
      "[0.9698835  0.03011651]\n",
      "[0.5643653  0.43563467]\n",
      "[0.7509767  0.24902333]\n",
      "[0.94564503 0.05435494]\n",
      "[0.9755089  0.02449108]\n",
      "[0.31061086 0.6893891 ]\n",
      "[0.13643579 0.86356425]\n",
      "[0.4073816 0.5926184]\n",
      "[0.07212819 0.9278718 ]\n",
      "[0.0136958 0.9863042]\n",
      "[0.8965987 0.1034013]\n",
      "[0.975684   0.02431604]\n",
      "[0.04927884 0.95072114]\n",
      "[0.22798389 0.7720161 ]\n",
      "[0.03028582 0.9697142 ]\n",
      "[0.8965987 0.1034013]\n",
      "[0.08692199 0.91307795]\n",
      "[0.9377278 0.0622722]\n",
      "[0.45919922 0.5408008 ]\n",
      "[0.22798389 0.7720161 ]\n",
      "[0.10440863 0.8955913 ]\n",
      "[0.02040021 0.97959983]\n",
      "[0.01513408 0.9848659 ]\n",
      "[0.13643579 0.86356425]\n",
      "[0.0136958 0.9863042]\n",
      "[0.9626742  0.03732581]\n",
      "[0.02744771 0.9725523 ]\n",
      "[0.16481704 0.83518296]\n",
      "[0.9698835  0.03011651]\n",
      "[0.9755966 0.0244034]\n",
      "[0.97585773 0.0241422 ]\n",
      "[0.975244   0.02475596]\n",
      "[0.0334073 0.9665927]\n",
      "[0.96875495 0.03124501]\n",
      "[0.9545044 0.0454956]\n",
      "[0.04927884 0.95072114]\n",
      "[0.01513408 0.9848659 ]\n",
      "[0.16481704 0.83518296]\n",
      "[0.07212819 0.9278718 ]\n",
      "[0.96758556 0.03241438]\n",
      "[0.5643653  0.43563467]\n",
      "[0.975684   0.02431604]\n",
      "[0.07920998 0.92079   ]\n",
      "[0.78835887 0.21164118]\n",
      "[0.9753327  0.02466736]\n",
      "[0.01121179 0.9887882 ]\n",
      "[0.45919922 0.5408008 ]\n",
      "[0.11426958 0.88573045]\n",
      "[0.96758556 0.03241438]\n",
      "[0.973511   0.02648904]\n",
      "[0.13643579 0.86356425]\n",
      "[0.9754209  0.02457906]\n",
      "[0.2672739  0.73272616]\n",
      "[0.8753112  0.12468877]\n",
      "[0.10440863 0.8955913 ]\n",
      "[0.9545044 0.0454956]\n",
      "[0.95669395 0.04330611]\n",
      "[0.0136958 0.9863042]\n",
      "[0.975771   0.02422897]\n",
      "[0.97303694 0.02696309]\n",
      "[0.9754209  0.02457906]\n",
      "[0.9720232  0.02797683]\n",
      "[0.10440863 0.8955913 ]\n",
      "[0.12493183 0.8750681 ]\n",
      "[0.9377278 0.0622722]\n",
      "[0.02744771 0.9725523 ]\n",
      "[0.78835887 0.21164118]\n",
      "[0.9754209  0.02457906]\n",
      "[0.9753327  0.02466736]\n",
      "[0.9755966 0.0244034]\n",
      "[0.0136958 0.9863042]\n",
      "[0.08692199 0.91307795]\n",
      "[0.0136958 0.9863042]\n",
      "[0.4073816 0.5926184]\n",
      "[0.97585773 0.0241422 ]\n",
      "[0.12493183 0.8750681 ]\n",
      "[0.0136958 0.9863042]\n",
      "[0.0123925  0.98760754]\n",
      "[0.0542484 0.9457516]\n",
      "[0.45919922 0.5408008 ]\n",
      "[0.0334073 0.9665927]\n",
      "[0.05424839 0.9457516 ]\n",
      "[0.02252648 0.9774735 ]\n",
      "[0.01121179 0.9887882 ]\n",
      "[0.0123925  0.98760754]\n",
      "[0.04474302 0.95525694]\n",
      "[0.7094256 0.2905744]\n",
      "[0.9755966 0.0244034]\n",
      "[0.0334073 0.9665927]\n",
      "[0.8753112  0.12468877]\n",
      "[0.6154145  0.38458553]\n",
      "[0.94207966 0.05792038]\n",
      "[0.93261105 0.06738893]\n",
      "[0.85037255 0.14962745]\n",
      "[0.8965987 0.1034013]\n",
      "[0.02252648 0.9774735 ]\n",
      "[0.975244   0.02475596]\n",
      "[0.05968765 0.9403123 ]\n",
      "[0.975684   0.02431604]\n",
      "[0.9755089  0.02449108]\n",
      "[0.975244   0.02475596]\n",
      "[0.94564503 0.05435494]\n",
      "[0.9753327  0.02466736]\n",
      "[0.19294864 0.80705136]\n",
      "[0.97461003 0.02538998]\n",
      "[0.8965987 0.1034013]\n",
      "[0.45919922 0.5408008 ]\n",
      "[0.13643579 0.86356425]\n",
      "[0.9750371 0.0249629]\n",
      "[0.7094256 0.2905744]\n",
      "[0.8214633 0.1785367]\n",
      "[0.5643653  0.43563467]\n",
      "[0.9247453  0.07525464]\n",
      "[0.96758556 0.03241438]\n",
      "[0.66404283 0.33595717]\n",
      "[0.5643653  0.43563464]\n",
      "[0.8965987 0.1034013]\n",
      "[0.12493183 0.8750681 ]\n",
      "[0.96448517 0.03551484]\n",
      "[0.08692199 0.91307795]\n",
      "[0.97603047 0.02396959]\n",
      "[0.04060684 0.9593932 ]\n",
      "[0.05968765 0.9403123 ]\n",
      "[0.9751551  0.02484488]\n",
      "[0.01513408 0.9848659 ]\n",
      "[0.2672739  0.73272616]\n",
      "[0.66404283 0.33595717]\n",
      "[0.9755966 0.0244034]\n",
      "[0.9759443  0.02405575]\n",
      "[0.08692199 0.91307795]\n",
      "[0.0136958 0.9863042]\n",
      "[0.9377278 0.0622722]\n",
      "[0.9626742  0.03732581]\n",
      "[0.96758556 0.03241438]\n",
      "[0.31061086 0.6893891 ]\n",
      "[0.19294864 0.80705136]\n",
      "[0.10440863 0.8955913 ]\n",
      "[0.9720232  0.02797683]\n",
      "[0.9732857  0.02671434]\n",
      "[0.4073816 0.5926184]\n",
      "[0.05424839 0.9457516 ]\n",
      "[0.96875495 0.03124501]\n",
      "[0.04474302 0.95525694]\n",
      "[0.04474302 0.95525694]\n",
      "[0.66404283 0.33595717]\n",
      "[0.9135783  0.08642175]\n",
      "[0.02744771 0.9725523 ]\n",
      "[0.97461003 0.02538998]\n",
      "[0.5643653  0.43563464]\n",
      "[0.04927884 0.95072114]\n",
      "[0.9709725  0.02902756]\n",
      "[0.04060684 0.9593932 ]\n",
      "[0.9247453  0.07525464]\n",
      "[0.9709725  0.02902756]\n",
      "[0.01847085 0.9815291 ]\n",
      "[0.12493183 0.8750681 ]\n",
      "[0.02486875 0.97513133]\n",
      "[0.04060684 0.9593932 ]\n",
      "[0.94564503 0.05435494]\n",
      "[0.0542484 0.9457516]\n",
      "[0.93261105 0.06738893]\n",
      "[0.97303694 0.02696309]\n",
      "[0.04060684 0.9593932 ]\n",
      "[0.9751551  0.02484488]\n",
      "[0.08692199 0.91307795]\n",
      "[0.97439384 0.02560617]\n",
      "[0.02040021 0.97959983]\n",
      "[0.94564503 0.05435494]\n",
      "[0.02252648 0.9774735 ]\n",
      "[0.01847085 0.9815291 ]\n",
      "[0.05424839 0.9457516 ]\n",
      "[0.96875495 0.03124501]\n",
      "[0.97461003 0.02538998]\n",
      "[0.04927884 0.95072114]\n",
      "[0.973956   0.02604396]\n",
      "[0.02040021 0.97959983]\n",
      "[0.95669395 0.04330611]\n",
      "[0.6154145  0.38458553]\n",
      "[0.94207966 0.05792038]\n",
      "[0.96875495 0.03124501]\n",
      "[0.04474302 0.95525694]\n",
      "[0.12493183 0.8750681 ]\n",
      "[0.973511   0.02648904]\n",
      "[0.14881887 0.85118115]\n",
      "[0.31061086 0.6893891 ]\n",
      "[0.973956   0.02604396]\n",
      "[0.9720232  0.02797683]\n",
      "[0.0368383 0.9631617]\n",
      "[0.97439384 0.02560617]\n",
      "[0.14881887 0.85118115]\n",
      "[0.96758556 0.03241438]\n",
      "[0.51191396 0.48808601]\n",
      "[0.94890416 0.05109582]\n",
      "[0.31061086 0.6893891 ]\n",
      "[0.02040021 0.97959983]\n",
      "[0.4073816 0.5926184]\n",
      "[0.95878255 0.04121742]\n",
      "[0.0953071 0.9046928]\n",
      "[0.04474302 0.95525694]\n",
      "[0.0136958 0.9863042]\n",
      "[0.9377278 0.0622722]\n",
      "[0.01672084 0.9832791 ]\n",
      "[0.0368383 0.9631617]\n",
      "[0.11426958 0.88573045]\n",
      "[0.5643653  0.43563464]\n",
      "[0.9755966 0.0244034]\n",
      "[0.04060684 0.9593932 ]\n",
      "[0.02744771 0.9725523 ]\n",
      "[0.05968765 0.9403123 ]\n",
      "[0.95669395 0.04330611]\n",
      "[0.9720232  0.02797683]\n",
      "[0.05968765 0.9403123 ]\n",
      "[0.9753327  0.02466736]\n",
      "[0.04474302 0.95525694]\n",
      "[0.05968765 0.9403123 ]\n",
      "[0.7094256 0.2905744]\n",
      "[0.7094256 0.2905744]\n",
      "[0.9737344  0.02626559]\n",
      "[0.66404283 0.33595717]\n",
      "[0.01672084 0.9832791 ]\n",
      "[0.97585773 0.0241422 ]\n",
      "[0.08692199 0.91307795]\n",
      "[0.08692199 0.91307795]\n",
      "[0.0368383 0.9631617]\n",
      "[0.9750371 0.0249629]\n",
      "[0.04060684 0.9593932 ]\n",
      "[0.97603047 0.02396959]\n",
      "[0.9753327  0.02466736]\n",
      "[0.07920998 0.92079   ]\n",
      "[0.2672739  0.73272616]\n",
      "[0.8753112  0.12468877]\n",
      "[0.01847085 0.9815291 ]\n",
      "[0.12493183 0.8750681 ]\n",
      "[0.07212819 0.9278718 ]\n",
      "[0.07920998 0.92079   ]\n",
      "[0.96448517 0.03551484]\n",
      "[0.0123925  0.98760754]\n",
      "[0.01121179 0.9887882 ]\n",
      "[0.2672739  0.73272616]\n",
      "[0.973956   0.02604396]\n",
      "[0.12493183 0.8750681 ]\n",
      "[0.9759443  0.02405575]\n",
      "[0.10440863 0.8955913 ]\n",
      "[0.01847085 0.9815291 ]\n",
      "[0.12493183 0.8750681 ]\n",
      "[0.975244   0.02475596]\n",
      "[0.0136958 0.9863042]\n",
      "[0.31061086 0.6893891 ]\n",
      "[0.6154145  0.38458553]\n",
      "[0.0136958 0.9863042]\n",
      "[0.78835887 0.21164118]\n",
      "[0.01847085 0.9815291 ]\n",
      "[0.9662113  0.03378867]\n",
      "[0.02252648 0.9774735 ]\n",
      "[0.0953071 0.9046928]\n",
      "[0.94207966 0.05792038]\n",
      "[0.22798389 0.7720161 ]\n",
      "[0.9698835  0.03011651]\n",
      "[0.0136958 0.9863042]\n",
      "[0.96077466 0.03922535]\n",
      "[0.0368383 0.9631617]\n",
      "[0.9755089  0.02449108]\n",
      "[0.973956   0.02604396]\n",
      "[0.04474302 0.95525694]\n",
      "[0.04060684 0.9593932 ]\n",
      "[0.12493183 0.8750681 ]\n",
      "[0.66404283 0.33595717]\n",
      "[0.01847085 0.9815291 ]\n",
      "[0.9698835  0.03011651]\n",
      "[0.0136958 0.9863042]\n",
      "[0.08692199 0.91307795]\n",
      "[0.95669395 0.04330611]\n",
      "[0.9751551  0.02484488]\n",
      "[0.96758556 0.03241438]\n",
      "[0.06563438 0.9343656 ]\n",
      "[0.97461003 0.02538998]\n",
      "[0.7094256 0.2905744]\n",
      "[0.6154145  0.38458553]\n",
      "[0.07920998 0.92079   ]\n",
      "[0.78835887 0.21164118]\n",
      "[0.9759443  0.02405575]\n",
      "[0.9751551  0.02484488]\n",
      "[0.12493183 0.8750681 ]\n",
      "[0.0334073 0.9665927]\n",
      "[0.11426958 0.88573045]\n",
      "[0.973956   0.02604396]\n",
      "[0.0953071 0.9046928]\n",
      "[0.02252648 0.9774735 ]\n",
      "[0.04474302 0.95525694]\n",
      "[0.0334073 0.9665927]\n",
      "[0.9662113  0.03378867]\n",
      "[0.9755089  0.02449108]\n",
      "[0.31061086 0.6893891 ]\n",
      "[0.9748244  0.02517555]\n",
      "[0.94564503 0.05435494]\n",
      "[0.9755966 0.0244034]\n",
      "[0.45919922 0.5408008 ]\n",
      "[0.9545044 0.0454956]\n",
      "[0.94207966 0.05792038]\n",
      "[0.02744771 0.9725523 ]\n",
      "[0.97303694 0.02696309]\n",
      "[0.02486875 0.97513133]\n",
      "[0.31061086 0.6893891 ]\n",
      "[0.0953071 0.9046928]\n",
      "[0.01672084 0.9832791 ]\n",
      "[0.93261105 0.06738893]\n",
      "[0.0368383 0.9631617]\n",
      "[0.45919922 0.5408008 ]\n",
      "[0.6154145  0.38458553]\n",
      "[0.8214633 0.1785367]\n",
      "[0.07920998 0.92079   ]\n",
      "[0.02040021 0.97959983]\n",
      "[0.31061086 0.6893891 ]\n",
      "[0.97303694 0.02696309]\n",
      "[0.66404283 0.33595717]\n",
      "[0.01847085 0.9815291 ]\n",
      "[0.22798389 0.7720161 ]\n",
      "[0.9732857  0.02671434]\n",
      "[0.96448517 0.03551484]\n",
      "[0.01513408 0.9848659 ]\n",
      "[0.8753112  0.12468877]\n",
      "[0.94890416 0.05109582]\n",
      "[0.96875495 0.03124501]\n",
      "[0.6154145  0.38458553]\n",
      "[0.02252648 0.9774735 ]\n",
      "[0.93261105 0.06738893]\n",
      "[0.95669395 0.04330611]\n",
      "[0.07212819 0.9278718 ]\n",
      "[0.35754576 0.6424542 ]\n",
      "[0.9748244  0.02517555]\n",
      "[0.97461003 0.02538998]\n",
      "[0.35754576 0.6424542 ]\n"
     ]
    }
   ],
   "source": [
    "for i in predictions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Each element in the predictions list is itself a list of length 2. The sum of the two values in each list is 1. The reason for this is because the two columns contain probabilities for each possible output: experienced side effects and did not experience side effects. Each element in the predictions list is a probability distribution over all possible outputs.\n",
    "\n",
    "* The first column contains the probability for each patient not experiencing side effects, which is represented by a 0. The second column contains the probability for each patient experiencing side effects, which is represented by a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "rounded_predictions = np.argmax(predictions, axis=-1)\n",
    "\n",
    "for i in rounded_predictions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the printed prediction results, we can observe the underlying predictions from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Creating Confusion Matrix For Neural Network Predictions\n",
    "\n",
    "\n",
    "\n",
    "Although we were able to read the predictions from the model easily, we werenâ€™t easily able to compare the predictions to the true labels for the test data.\n",
    "\n",
    "With a confusion matrix, weâ€™ll be able to visually observe how well the model predicts on test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Plotting A Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the confusion matrix and assign it to the variable cm.\n",
    "cm = confusion_matrix(y_true=test_labels, y_pred=rounded_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we have a function called plot_confusion_matrix() that came directly from scikit-learnâ€™s website. This is code that they provide in order to plot the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_plot_labels = ['no_side_effects','had_side_effects']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[200  10]\n",
      " [ 10 200]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAEmCAYAAADBbUO1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3debyd09n/8c83CRESIkiEiJiHBlFKzUFNFUNbagqhWkN5aEs9qapZTdHBU6X8zDFTRGoKaqwYQoiUGBpaREbzkEpcvz/WOrEdJ/vsM+0p37fX/Tp7r30Pa28511n7WuteSxGBmZmVR6dKV8DMbEHioGtmVkYOumZmZeSga2ZWRg66ZmZl5KBrZlZGDrpWcyR1k3SHpPcl3dSG8+wn6d72rFslSLpL0rBK18NK46BrHUbSvpKelvSRpCk5OGzeDqfeA+gDLBURe7b2JBFxTURs3w71+QpJgyWFpL82Kl8vlz9Y4nlOljSyuf0iYqeIuLKV1bUyc9C1DiHpF8AfgN+SAmR/4M/Abu1w+hWBlyNiTjucq6NMBzaVtFRB2TDg5fa6gBL/DteaiPDmrV03YAngI2DPIvt0JQXlt/P2B6Brfm0w8CZwDDANmAIclF87Bfgv8Hm+xsHAycDIgnMPAALokp8fCPwL+BCYDOxXUP5owXGbAk8B7+efmxa89iBwGvBYPs+9wNLzeW8N9b8IOCKXdc5lJwIPFuz7R+A/wAfAOGCLXL5jo/f5XEE9zsj1+BRYNZf9OL9+IXBzwfnPBu4HVOl/F97S5r+S1hE2ARYBbi2yz6+BbwODgPWAjYATCl5flhS8lycF1gskLRkRJ5FazzdERPeIuLRYRSQtBpwP7BQRPUiBdXwT+/UC/pb3XQr4HfC3Ri3VfYGDgN7AwsCxxa4NXAUckB/vAEwk/YEp9BTpM+gFXAvcJGmRiLi70ftcr+CY/YFDgB7AG43OdwywrqQDJW1B+uyGRY7AVnkOutYRlgJmRPGv//sBp0bEtIiYTmrB7l/w+uf59c8j4k5Sa2+NVtbnC2CgpG4RMSUiJjaxz87AKxFxdUTMiYjrgJeAXQr2uTwiXo6IT4EbScFyviLiH0AvSWuQgu9VTewzMiJm5mueR/oG0Nz7vCIiJuZjPm90vk+AoaQ/GiOB/4mIN5s5n5WRg651hJnA0pK6FNlnOb7aSnsjl807R6Og/QnQvaUViYiPgb2Aw4Apkv4mac0S6tNQp+ULnr/TivpcDRwJbE0TLX9Jx0h6MY/EeI/Uul+6mXP+p9iLEfEkKZ0i0h8HqyIOutYRHgc+A3Yvss/bpA6xBv35+lfvUn0MLFrwfNnCFyPinojYDuhLar1eUkJ9Gur0Vivr1OBq4KfAnbkVOk/++v+/wA+BJSOiJymfrIaqz+ecRVMFko4gtZjfBo5rfdWtIzjoWruLiPdJHUYXSNpd0qKSFpK0k6Rz8m7XASdIWkbS0nn/ZodHzcd4YEtJ/SUtAfyq4QVJfSTtmnO7s0lpirlNnONOYPU8zK2LpL2AtYHRrawTABExGdiKlMNurAcwhzTSoYukE4HFC16fCgxoyQgFSasDp5NSDPsDx0kqmgax8nLQtQ4REb8DfkHqHJtO+kp8JHBb3uV04GngeWAC8Ewua821xgA35HON46uBshOpc+ltYBYpAP60iXPMBIbkfWeSWohDImJGa+rU6NyPRkRTrfh7gLtIw8jeIH07KEwdNNz4MVPSM81dJ6dzRgJnR8RzEfEKcDxwtaSubXkP1n7kTk0zs/JxS9fMrIwcdM3MAEkrSPp7Hk0yUdLRubyXpDGSXsk/l8zlknS+pFclPS/pm6Vcx0HXzCyZAxwTEWuRbtw5QtLawHDg/ohYjXR33/C8/07Aank7hHQ3YLMcdM3MgHzjzDP58YfAi6Rx2rsBDRMKXcmXQyF3A66KZCzQU1Lf5q5TbPC61QB16RZauEelq1G31l+rf6WrUNfeeON1ZsyYoeb3bF7nxVeMmPNp0X3i0+kTSaNEGlwcERc33k/SAGB94AmgT0RMgRSYJfXOuy3PV0ebvJnLphSrg4NujdPCPei6xg8rXY269dgTf6p0FeraZhtv2G7nijmfNvu78Nn4Cz6LiKIXldQduAX4WUR8IM33b0JTLzQ7HMxB18zqgwSdOrfxFFqIFHCviYiG+ZCnSuqbW7l9STPfQWrZrlBweD9KuKvSOV0zqx/qVHwrdmhq0l4KvJhv7mkwijQXMvnn7QXlB+RRDN8G3m9IQxTjlq6Z1Yk2t3Q3I906PUFSw/SfxwNnATdKOhj4N9CwWsmdwHeBV0kTIB1UykUcdM2sfsw//9qsiHiUpvO0ANs2sX8AR7T0Og66ZlYf2iGnWw4OumZWP2pgyTgHXTOrE27pmpmVj2hTTrdcHHTNrH44vWBmVi6Czk4vmJmVh3BL18ysfNyRZmZWXu5IMzMrE98cYWZWZs7pmpmVi1u6Zmbl5ZyumVmZeMiYmVk5tcvKEZcBQ4BpETEwl90ArJF36Qm8FxGD8jpqLwKT8mtjI+Kw5q7hoGtm9aPtLd0rgD8BVzUURMRe804vnQe8X7D/axExqCUXcNA1s/rQDkPGIuLh3IJt4vQS8ENgm7Zco/oTIGZmpZKKb22zBTA1Il4pKFtJ0rOSHpK0RSkncUvXzOqCgE6dmm1HLi3p6YLnF0fExSVeYh/guoLnU4D+ETFT0gbAbZK+EREfFDuJg66Z1Qcx/xXOvjQjIjZs8amlLsD3gQ0ayiJiNjA7Px4n6TVgdeDpJk+SOeiaWZ1QKS3d1voO8FJEvDnvatIywKyImCtpZWA14F/Nncg5XTOrG5KKbiUcfx3wOLCGpDfzsusAe/PV1ALAlsDzkp4DbgYOi4hZzV3DLV0zqw8CdWpbZ1lE7DOf8gObKLsFuKWl13DQNbO6IEprzVaag66Z1Q0HXTOzMurAjrR246BrZvWhtCFjFeega2Z1QR07ZKzdOOiaWd1wTtfMrFzaYchYOTjomlndqIWWbvUnQKxm9OvTk7svPopnbzmBcTf/miP2GQzAkosvyugLj2TC7Scy+sIj6dmj27xjzjtuD164/SSevOFXDFqzX4VqXpsO/fGP6L9cbzYYNHBe2axZs9h5x+0YuNZq7Lzjdrz77rsVrGF5NeR0i23VoDpqYXVhztwvGP67v7L+D05nqwNGcOheW7Lmysty7EHb8eCTk1hnt1N58MlJHHvQ9gDssPnarNJ/GQbudgpHnn4d5x+/d4XfQW3Zf9iB3D767q+UjTjnLAZvsy0vvPgKg7fZlhHnnFWh2lWImtmqgIOutZt3ZnzA+JfSfCAffTKblya/w3LL9GTI4HUZeccTAIy84wl22XpdAIZstS7Xjn4SgCcnvM4SPbqx7NKLV6byNWjzLbakV69eXykbfcftDN1/GABD9x/GHaNuq0TVKkNtn3uhHBx0rUP079uLQWv046kXXqf3Uj14Z0aaYvSdGR+wTK8eACzXuydvvvPl19+3pr7Hcr17VqS+9WLa1Kn07dsXgL59+zJ92rQK16i8aiG94I40a3eLdVuY60b8mF+OuIUPP/5svvs11fCIiA6smdW96mjMFlUdob+dSNpV0vD5vPZRO19rT0kvSvp7fn6dpOcl/byF5+kp6aftWbdK6tKlE9eN+Ak33PU0tz/wHADTZn44L22w7NKLM33Wh0Bq2fZbdsl5xy7fpydTpr//9ZNayXr36cOUKVMAmDJlCsv07l3hGpWP5I60souIURFRrp6Dg4GfRsTWkpYFNo2IdSPi9y08T0+gboLuRSftx6TJ73D+yAfmlf3toQkM3WVjAIbusjGjH3x+Xvm+QzYCYKN1BvDBR5/OS0NY6+w8ZFdGXn0lACOvvpIhu+xW4RqVl3O68yFpQG4lXiJpoqR7JXWTNEjS2NxivFXSkkXOcZSkf+Z9r89lB0r6U368kqTHJT0l6bRGx/4ylz8v6ZRm6jpU0pOSxkv6i6TOkk4ENgcuknQucC/QO++zhaRVJN0taZykRyStmc/VJ7+v5/K2KXAWsEo+9lxJfSU9nJ+/UOpid9Vg00Ers9+QjdnqW6sz9vrhjL1+ODtsvjYjLh/DNhuvyYTbT2SbjddkxOVjALj70YlMfnMmE0edxAW/2Zejz7yxwu+gthwwdB8Gb7EJL0+axCoD+nHFZZdy7HHDeeC+MQxcazUeuG8Mxx7X5Be/uqVOKro1e7x0maRpkl4oKDtZ0lv5d3K8pO8WvPYrSa9KmiRph5LqWIkcWl7i+FVgw4gYL+lGYBRwHPA/EfGQpFOBxSPiZ/M5x9vAShExW1LPiHhP0oH5nEdKGgXcHBFXSToCODsiukvaHtgDOJSUARoFnBMRDzdxjbWAc4DvR8Tnkv4MjM3nfBA4NiKezu9ndEQMzMfdT5pF/hVJGwNnRsQ2km4AHo+IP0jqDHQHlmx07DHAIhFxRt5n0Yj4sFG9DgEOAWCh7hss8o1hLfsfYCV796k/VboKdW2zjTdk3Lin26UJ2rXParH8fn8sus/k3+88rtgaaZK2BD4Crir4nTwZ+CgiRjTad23SahIbAcsB9wGrR8TcYnWoZEfa5IgYnx+PA1YBekbEQ7nsSuCmIsc/D1wj6TagqXExmwE/yI+vBs7Oj7fP27P5eXfS2kZfC7rAtqSF6J7KX026AUW7gyV1BzYFbir4OtM1/9wGOAAg/495v4nW/FPAZZIWAm4r+IzmyauXXgzQadHe7nkyI3XMdmr7yhEP50ZUKXYDrs8LVE6W9CopAD9e7KBKBt3ZBY/nknKbLbEzaY2iXYHfSPpGE/s0FZBEann+pYRrCLgyIn7Vgnp1At6LiEEtOGae/D99S9L7u1rSuRFxVWvOZbZgKSlv29ol2I+UdABppd9jIuJdYHlgbME+b+ayoqqpI+194N2CHOb+wENN7SipE7BCRPydlJLoSWqxFnqMtJgcwH4F5fcAP8otUiQtL2l+Xbz3A3s0vC6pl6QVi72JvOb9ZEl75mMkab2C8x2eyztLWhz4EOhR8N5WBKZFxCXApcA3i13PzL7UqZOKbuQl2Au2UgLuhaRv4oOAKcB5ubypCN/sN89qCroAw4BzJT1PeoOnzme/zsBISRNIaYLfR8R7jfY5GjhC0lPAEg2FEXEvcC3weD7+ZgqCXqGI+CdwAnBvrtMYoG8J72M/4GClVUInkr6GNNRp63zdccA3ImIm8FjuNDsXGAyMl/QsKT1SPEllZolSiqHY1hoRMTUi5kbEF8AlpBQCpJbtCgW79gPebraaHoxe2zot2ju6rvHDSlejbrkjrWO1Z0dat76rx0oHFf//9eKZOxTtSIN5Hf2Fndt9I2JKfvxzYOOI2DunNK/ly460+4HVqrkjzcysXbW1I03SdaRvm0tLehM4CRgsaRApdfA6aeQTETExj7z6JzAHOKK5gAs1EHQlXUAaiVDojxFxeTteYynSX6nGts1f/82s2rUhhdAgIvZpovjSIvufAZzRkmtUfdCNiCPKcI2ZpByymdUor5FmZlZmVXKnb1EOumZWH9rh5ohycNA1s7ogamONNAddM6sbbumamZVRDTR0HXTNrE7I6QUzs7JJQ8YcdM3MyqYGGroOumZWJzxkzMysfDxkzMyszGq6pZsn2J6vPFm3mVnVqPWW7kTSVGaF76LheQD9O7BeZmYtItX46IWIWGF+r5mZVaO2NnQlXQYMIS2Z1TCJ+bnALsB/gdeAg/Lq4wOAF4FJ+fCxEXFYc9coaR40SXtLOj4/7idpgxa+FzOzDte5k4puJbgC2LFR2RhgYESsC7wMFC5U+1pEDMpbswEXSgi6kv4EbE1aKBLgE+CiUk5uZlYuynekFduaExEPA7Mald0bEXPy07GktdBarZSW7qYRcSjwWa7ALGDhtlzUzKwjdFLxjbwEe8F2SAsv8SPgroLnK0l6VtJDBSuZF1XKkLHP85LnAfOWtvmihRU1M+twJXSkzWhuYcr5kfRr0lpo1+SiKUD/iJiZU663SfpGcyO7SmnpXgDcAiwj6RTgUeDs1lTazKyjiDT/QrH/Wn1uaRipg22/yEuoR8TshjUUI2IcqZNt9ebO1WxLNyKukjQO+E4u2jMiXmht5c3MOoRK7ixr4Wm1I/C/wFYR8UlB+TLArIiYK2llYDXgX82dr9Q70joDn5NSDNW/8puZLZDaYchYU0uw/wroCozJnXENQ8O2BE6VNAeYCxyW+7yKajbo5jzGvsCtpBb8tZKuiYgzW/WuzMw6gKDNLd2WLMEeEbeQUq8tUkpLdyiwQUOzWtIZwDjAQdfMqkqt3wbc4I1G+3WhhLyFmVk5SW1v6ZZDsQlvfk/K4X4CTJR0T36+PWkEg5lZVan+kFu8pdswQmEi8LeC8rEdVx0zs9ar6fRCRDSZPDYzq0bqoCFj7a2U0QurAGcAawOLNJRHRLODgM3MyqkGGroljbm9AriclC7ZCbgRuL4D62Rm1mINQ8baOMtYhysl6C4aEfcARMRrEXECadYxM7Oq0tZZxsqhlCFjs5Vq+5qkw4C3gN4dWy0zs5aRoHOVBNZiSgm6Pwe6A0eRcrtLkKY3MzOrKjUQc0ua8OaJ/PBDvpzI3Mys6tT0GmmSbiXPoduUiPh+h9TIzKwVhOhUA03dYi3dP5WtFtZq66/Vn8ee8P+qjrLkt46sdBXq2uxJ/26/k6nGW7oRcX85K2Jm1la1MO9sLdTRzKxZou1DxiRdJmmapBcKynpJGiPplfxzyVwuSedLelXS85K+WUo9HXTNrG506VR8K8EVfH0J9uHA/RGxGnB/fg7pZrHV8nYIcGEpFyg56ErqWuq+Zmbl1lFLsAO7AVfmx1cCuxeUXxXJWKCnpL7NXaPZoCtpI0kTgFfy8/Uk/V+ztTczK7POnYpvtG4J9j4RMQUg/2y4OWx54D8F+72Zy4oq5eaI80mrYN6WL/qcJN8GbGZVRVDKkLFWL8E+n0s2Nt9htg1KSS90iog3GpXNLalKZmZl1FnFt1aa2pA2yD+n5fI3gRUK9usHvN3cyUoJuv+RtBEQkjpL+hnwcsvqbGbWsaR0c0SxrZVGAcPy42HA7QXlB+RRDN8G3m9IQxRTSnrhcFKKoT8wFbgvl5mZVZXObRyPNZ8l2M8CbpR0MPBvYM+8+53Ad4FXScuaHVTKNUqZe2EasHdLK29mVk4l5nSLms8S7ADbNrFvAEe09BqlrBxxCU0khyOilF4/M7OyqYGpF0pKL9xX8HgR4Ht8dZiEmVnl1ct8uhFxQ+FzSVcDYzqsRmZmrZDSC5WuRfNKaek2thKwYntXxMysraplHbRiSsnpvsuXOd1OpFvkhs//CDOz8quLlm5eG2090rpoAF/kHjszs+qi2mjpFh3VlgPsrRExN28OuGZWlRpausW2alDKUOInS50n0sysckRnFd+qQbE10rpExBxgc+Ankl4DPib9QYmIcCA2s6qRJjGvdC2aVyyn+yTwTb6cO9LMrHoJulRLDqGIYkFXABHxWpnqYmbWavXQ0l1G0i/m92JE/K4D6mNm1mq1vgR7Z6A7TU/Ua2ZWVUSb5swtm2JBd0pEnFq2mpiZtUVeI63aNZvTNTOrBaml27awJWkNoHC+mZWBE4GewE+A6bn8+Ii4szXXKBZ0vzZ/pJlZNWtrSzEiJgGDACR1Jt2NeytpgvLfR8SINl5i/kE3IhovQ2xmVsVEp/YdMrYt8FpEvNGeaYs2Lm5hZlYdRApoxbYW2hu4ruD5kZKel3SZpCVbW08HXTOrGyUsTLm0pKcLtiZXwJG0MLArcFMuuhBYhZR6mAKc19o6tmY+XTOz6lPa6IUZEbFhCWfbCXgmIqYCNPyEeUuYjW5tNd3SNbO60M7phX0oSC1I6lvw2veAF1pbT7d0zaxutMcdaZIWBbYDDi0oPkfSINKCDq83eq1FHHTNrG60xyCDiPgEWKpR2f5tP3PioGtmdaE9bo4oBwddM6sTQjVwI62DrpnVBbd0zczKSbUxn66HjFmHOfTHP6L/cr3ZYNDAeWWzZs1i5x23Y+Baq7Hzjtvx7rvvVrCGtadfn57cffFRPHvLCYy7+dccsc9gAJZcfFFGX3gkE24/kdEXHknPHt3mHXPecXvwwu0n8eQNv2LQmv0qVPPyKOHmiIpz0LUOs/+wA7l99N1fKRtxzlkM3mZbXnjxFQZvsy0jzjmrQrWrTXPmfsHw3/2V9X9wOlsdMIJD99qSNVdelmMP2o4Hn5zEOrudyoNPTuLYg7YHYIfN12aV/sswcLdTOPL06zj/+L0r/A46Tj2tBmzWKptvsSW9evX6StnoO25n6P7DABi6/zDuGHVbJapWs96Z8QHjX3oTgI8+mc1Lk99huWV6MmTwuoy84wkARt7xBLtsvS4AQ7Zal2tHPwnAkxNeZ4ke3Vh26cUrU/kycEvXrJFpU6fSt2+6uadv375MnzatwjWqXf379mLQGv146oXX6b1UD96Z8QGQAvMyvXoAsFzvnrz5zpcpnLemvsdyvXtWpL7loGb+qwbuSDOrQYt1W5jrRvyYX464hQ8//my++zXVuIuIDqxZ5TSkF6pdh7V0JQ2Q1Or7kyV91Ipj7pT0tT/jkk6WdGxr69LE+bpKuk/SeEl7SdpC0sT8vFvzZ/jKuXaXtHZ71a3a9e7ThylTpgAwZcoUlundu8I1qj1dunTiuhE/4Ya7nub2B54DYNrMD+elDZZdenGmz/oQSC3bfst+OQvh8n16MmX6++WvdDk0k1pweqEDRMR3I+K9MlxqfWChiBgUETcA+wEj8vNPW3iu3YEFJujuPGRXRl59JQAjr76SIbvsVuEa1Z6LTtqPSZPf4fyRD8wr+9tDExi6y8YADN1lY0Y/+Py88n2HbATARusM4IOPPp2XhqhHamarBh0ddDtLuiS3Au+V1E3STyQ9Jek5SbfkySWQtJKkx/NrpxU7qaS+kh7OLcsXJG2Ry1+XtHR+/GtJkyTdB6xRcOwqku6WNE7SI5LWLHKdZXIdn8rbZpJ6AyOBQfn6hwI/BE6UdE0+7pd5/+clnVJwvgNy2XOSrpa0KWnOznPzuVaRdJSkf+b9rp9PvQ5pmA90+ozpTe1SFQ4Yug+Dt9iElydNYpUB/bjisks59rjhPHDfGAautRoP3DeGY48bXulq1pRNB63MfkM2Zqtvrc7Y64cz9vrh7LD52oy4fAzbbLwmE24/kW02XpMRl48B4O5HJzL5zZlMHHUSF/xmX44+88YKv4OO03BzRLGtGqij8juSBgCvAhtGxHhJNwKjgLsiYmbe53RgakT8n6RRwM0RcZWkI4CzI6L7fM59DLBIRJyR1zFaNCI+lPQ6sCGwInAFsDEpb/0McFFEjJB0P3BYRLwiaWPgzIjYZj7XuRb4c0Q8Kqk/cE9ErCVpMHBsRAzJ+10BjI6ImyVtD+xBmoVI+T2fA8wE/gpsFhEzJPWKiFmFx+ZzvQ2sFBGzJfVsruW+wQYbxmNPPF1sF2uDJb91ZKWrUNdmT7qRLz6Z1i7RcK111o/Lb/t70X02WXXJcSXOp9thOrojbXJEjM+PxwEDgIE52PYEugP35Nc3A36QH18NnF3kvE8Bl0laCLit4BoNtgBuzbMFkQM6kroDmwI3FUx23LXIdb4DrF2w7+KSehTZH2D7vD2bn3cHVgPWI/1RmQFF16B7HrhG0m2Ax1OZtUC15G2L6eigO7vg8VygG6kFuntEPCfpQGBwwT4lNbsj4mFJWwI7A1dLOjcirmq8WxOHdgLei4hBpVWfTsAmjfO0zcxOL1Lr+S+NjjlqPnVqbGdgS1La4TeSvhERc0qsr9kCrfpDbmU60noAU3Irdb+C8sdIC8HRqPxrJK0ITIuIS4BLgW822uVh4Hs5h9wD2AUgIj4AJkvaM59HktYrcql7gXnfL/Mkxs25B/hRblUjafmcB74f+KGkpXJ5w10DH5I+EyR1AlaIiL8Dx/HltwEza4ZIDaJiW0nnSX1DE3I/y9O5rJekMZJeyT9ramHK3wBPAGOAlwrKjwaOkPQUsEQz5xgMjJf0LCkl8cfCFyPiGeAGYDxwC/BIwcv7AQdLeg6YCBTrPj8K2DB3av0TOKyZehER9wLXAo9LmgDcDPSIiInAGcBD+dq/y4dcD/wyv5fVgJH5uGeB35dpNIZZ7csT3hTbWmDrPBqpIf87HLg/IlYjNaBa3QPcYR1pVh7uSOtY7kjrWO3Zkbb2uuvHyFEPFd1ng5WWaLYjraFDvqH/JZdNAgZHxBSl9dIejIg15neOYupqnK6ZLciKpxZU+hLsAdybh5U2vN4nIqYA5J+tvqunqm8DlrQOaSRDodkRsXE7X+fXwJ6Nim+KiDPa8zpm1rFKSCGUsgT7ZhHxdu6LGSPppWb2b5GqDroRMQEodaRBW65zBinfamY1KnWktf08EfF2/jlN0q3ARsBUSX0L0gutnqnJ6QUzqxttnWVM0mINY/ElLUYac/8C6SanYXm3YcDtra1jVbd0zcxaoh1mGesD3Jrzv12AayPi7jyq6kZJBwP/5uvpyJI56JpZfWiHWW0i4l+ku0cbl88Etm3b2RMHXTOrC2k+3eq/J81B18zqRvWHXAddM6sjpd7qW0kOumZWN2og5jromln9qIGY66BrZvWhYZaxauega2b1oeUziVWEg66Z1Q0HXTOzsintVt9Kc9A1s7qQbo6odC2a56BrZvXDQdfMrHx8G7CZWRlVf8h10DWzelEjQ8Y8ibmZ1YW2LsEuaQVJf5f0oqSJko7O5SdLeisvyT5e0nfbUk+3dM2sbrSxoTsHOCYinsmrR4yTNCa/9vuIGNHG6gEOumZWR9rSkZZX+W1Y8fdDSS8Cy7dT1eZxesHM6oea2Upbgh1JA4D1gSdy0ZGSnpd0maQl21JFB10zqwtSujmi2EZegr1gu/jr51F34BbgZxHxAXAhsAppZfIpwHltqaeDrpnVjXZYDXghUsC9JiL+ChARUyNibkR8AVxCWpK91Rx0zaxuSMW34sdKwKXAixHxu4LyvgW7fY+0JHuruSPNzOpGG8fpbgbsD0yQND6XHQ/sI2kQEMDrwKFtuYiDrpnVBaG2jl54lKZHnd3Z6pM2wekFM7MyckvXzOpGLYBKw1UAABFFSURBVNwG7KBrZvVBnmXMzKxsvrz/obo56JpZ3fBqwGZmZVQDMddB18zqh4OumVkZ1cJqwIqIStfB2kDSdOCNStejBZYGZlS6EnWs1j7fFSNimfY4kaS7Se+/mBkRsWN7XK+1HHStrCQ9HREbVroe9cqfb/XzHWlmZmXkoGtmVkYOulZuX5s02tqVP98q55yumVkZuaVrZlZGDrpmZmXkoGtmVkYOumZmZeSga2ZWRg66VvPyKq5I+qakNVUL8/vVqILPetlK16VWOehazYuIkLQTcBOweHgcZIeQpPxZ7whcKWlF/4FrOY/TtZpVEARWIq3YuldEPC9pDaAn8EJEfFzZWtYXSVsClwEHRMQ/JHWLiE8rXa9a4qBrNUfSYsAiETFT0mrAB8AvgM+BzsAWwHTgnoi4qHI1rX2SupC+TMyVtBBwOOlzvhbYE/gx8EREHF3BatYUpxesFq0J/FnS4cDvgeWAF4EVgIeBXYD7gXaZMnBBJakr6Q/YipJ2A4YCE4DTSKmcJYBfA5tIWr9iFa0xnsTcak5EjJP0IXAecHhEPCtpInBlTjdsBBwEHF/Rita+/wKrAb8BBgCHRcTfJW0GzIqI6ZL6k75dfFi5atYWt3StZhT0nPcitWz/AhwuaZ2I+G8OuBuSUg2nR8Q97uhpHUmdcofk7aSg+gIwRdKiETEpB9w9gXtIn/WrlaxvLXFO12pK/pq7F/C/EfEfSceRcos7AV2BfYHr82vySIaWK+ig3BYYCFwD/ISUvrk5Ih6QtASwDtA1Iu73Z106t3StZkjaBDgJuCAi/gMQEecANwNjSXncZwpecxBohRxwh5Dy5S9FxAzgXNIyQN+TdCLwLPCfiLi/4ZiKVbjGuKVrNUPSPsB6ETFc0iLAbJgXJDYCPo+IZytayTqQP9uLgUsi4hFJC0fEf/NIhn2BbwCPRsQdFa1ojXJHmlWtJr6yfk76hSciPsv7bCKpc0Q8Wok61qm5wFKkUSKPkD53gH4RcVXDTk4ptI7TC1aVciANSdtJ+omkQyPiZmAJSZdLWlnSd0j5Rv87boOCDsqVJa1MCrpXkIaKbZL/P3wbuELSqg3HOeC2jlu6VlUkLRYRH+fB+N8FTgd+Bfwl3xSxNXADXw5jOjIiHq5YhWtcHqXwhaTdgWOBN4BpwKPAJ8CZkl4DtgR+7lEKbeecrlUNSWsBPyMF2reAC4GzST3oxwH7R8Tkgv2XjogZ/prbcpLWBHpExFOSVgf+H7AjcDSwK7A50ANYlvTH7Z2IGO/Puu3c0rWqIGlh4HfABcA7pF/2z0lBYCDwo4iYLOmHpA6zW4FZ4K+5LZVnCHsIOCAXfQQ8DuxNuptv//xNY5WIGAe81HCsP+u2cy7MKi5PWNMV+DvwW9JwpKmkQHAEMCIiXs55xVPya0TEF5Wpce3KKZqlSHMnLCXpCmAhUmv2F6Q/bq9K2oF0q3W/StW1XjnoWkVJWhF4jNRT/iSwPPBpRMyNiGtIgeDPkv5ESjccFxH/qFiFa5iktUm3Ts8GVgUuAh6MiDeAe4F/AEMlDSWN0T0tIt6sVH3rlXO6VlF5HtxtSC2vfYG/AbsBawPfi4hPJG1KmkmsU5660XnFFspjb28FRkXEhZKOATYBxgG3kVII25JyuQuRgvEYf9btz0HXKirnF8eQWri7R8TD+Svw73PZHp6vtX1I2g84CugDDCLNqXAG8D5weUS8lPfrHBFzK1bROuf0glVMHq70DqmVNRnoJ6lHnnj8KGAmMMqT1rSb6cB6pGFhioiZpKC7KHCIpG/m/Zwr70Bu6VrZNVrx4R3SL3130oD8m0hTNH6cvxKvGhEvVK62ta0wPZAnqVkZ2Cpvx0fEizmvfjxwXkS8XLnaLhgcdK0iJO1KGnv7LCDSZNhrAaeS8rqXRsRHlath7Sv447YzKX/bHTgBWBj4KbAucHJE/FNS14iYXcHqLjCcXrCyy4PxTyCNCf2E1GnWKSLGAicCPwB6Va6G9aHhNmrSMLvrge2BP0XELOBSYBLpjrPF+HJ+BetgvjnCKmExUufZ5qTbS4dGxLuSNoyIsZJ2iYj3K1vFurElcBiwIvAuaWpMSGmd84Clw4t3lpWDrlXCZOBbpMnIt84Tju8I/ELS/hExtbLVqyuzgZ+TRiwcGBFv5Cky+0TEH4D3Klq7BZDTC1YJH5EmHr8XODDnHM8lffV1wG1f9wM7ANdFxCv5rr7fkJbfsQpwR5pVRF7nbB1gf9LQsIci4k4Pxm8/BR1p3wXOBMYDqwO/9QTkleOgaxVXML2gA247Kwi8K5BSDYvliYP8WVeIg661u4Jf9DWARYDX59cx1mgcqQNBCxV81p2BL0r9/HzXWeU46FqHyJNi/4q0VHpX4I95SFjhPp3zFII9gO4RMaUCVa1Zjcbh7kuan+LBiLihiX0bPuuFIsLDwyrIHWnWLiR1yj87SxpAGny/NWkGsVWBSYW38xYEgSVIc7suV/ZK17gccLcFTgbOIY1GOirPTTxPwWfdE7ggz3dhFeKga20mqTfwVF7JYS7p39UE4FDgIGDviHgX+LakRRsF3L8CR+XJsq0ZkpaRtEtBUT/gcGAF0qKd+0ZauXf5vH/hZ30rMDLPd2EV4qBrbRYR04CxwKOSekXEv4DFgR8Bh0fEa7lFdhHQtyAI3AucFF7JtyT528QPgN0kfT8XL0aas+IY0lSYb+Qxz0dK6l7Qwr0d+E14PbmKc07X2kRSl4iYI2lp4C7Sff2bk2az+jFpTO7LpNbYLyNidD5uM9Ktv49Upua1pVGH4/GkdMzNpNTM7aTf5V0kbQ/8kbSI5N2SFiJNk3mjA251cNC1NpM0BPglcCWpQ6cfsAHQF9gJ6AY8GREPNuR1PUqhdfI3hmNId5hNJQXYx0hL0X8OLAOcHRF3FhyzTERMr0B1rQkOutZiuSOmf0Q8mZ9fCDwXERfl5xcAmwLb5DkVPCyslQpHGyitV3YbsA9pmfRDgf6ku80ey8PGloyIGXl/DwurQs7pWotI6gIMBj6Q1D0XzwSWzK+LtIR6T+CJvP+8f2cOuKXLKZur8rzC8OVcKXPzuOf/R2rx/lbSHjnAzmw43gG3Ormlay0mqRupA+cc0i/+LOBR4MiIuF7SRqTA/FBEPFGxitYBSSuTgq0iYpKkM0mB9caI+LekPUlryp0SEa9Usq5WGrd0rWQNY3FJk45/TpqP9UDS8i7bASdIuoy0+sOzDritl1MF5JEg+wJ355U2RpFatxdI+hlp8pq/OODWDrd0rSQFdz/tABxAGg62HKmVtR5wNvAWKa2weERMrFhla1zBZ/1t4OOImCDpZGBnYA/gM+C7wErAwxFxX+Vqay3loGslywH3fNLY2wdy2WLAwcC3SSvKjqlgFeuG0tL0FwDDGobVSToR2BXYL6caOkWEF5GsMZ7E3EpS0IH2U+BxST8EDiENWbqKtJy373RqB0oLRZ4N/CAinpU0COgREadKCuBWSRsCXpq+BrmlayWTdDQwHHgGeAL4LynfuCXpa7AnUmkHuaPyFNKNJgEMIt1kcm9E/J+k1cOr9tYst3StZBHxR0kvApPy7aZ9SXnGRSPCy760ny+Ap4EtSB1nw0mTvQ/Mr79aoXpZO3BL10rSOH+otM7W8aS5E/5auZrVvuZuYpC0MfBn4ISIuKt8NbOO4CFjVpImOmw6A/8bEX8tnLLRSiNpJUnnQbqJoWGIWBP7rQP8DDgtIu7yZ1373NK1eQqGKi1HGoC/UER85F7y9pdHfbwG3BQR/5PLvtbizRPWLBUR73jeivrglq7NkwPujsAtpGkYL5O0aqT1y+b9W8kjGZDUTdKqFapuzZK0cER8DGwPDJV0Lsy3xTunIeA62NYHB12bR9LqwB+A40irxz4JXCNphYaWbm6NzSmYo9X/hlooTzK+G2lmtkuAYZL+kl+bF3jzZx2SlgSultTVgbf2+RdmAdcoRzgbeCQPxn81IkaQhoZtk/ftUjAp9o3AGR661HKSFiXlaW+KiONIy6IPlvQ7mBd4Cz/rG4DLImJ25Wpt7cVDxhZwuSW1FbAm8Aaws6SDIuLyvMt7wFJ53zl5xYfbSKsQeALy1vkM+BdpPlwi4j1JvwDuyK3bo/NnvSQp4J7mz7p+OOguoAo6zRqGI00C/klas+wMpXXPXiHddvrzgkOHAb+KiMfLXedaVfBZLx8Rb+Uc+YvAlZLWj4hPSR2XJwP/yMd0IU0Kf6YDbn3x6IUFWJ6C8VTguIh4XtJQYGVgWdIKBC+SVnwYXRA4PDF2Kygtk3488AgwPSLOk/Rb0sQ195HWPtsnIsbmlE8XoKdXfKg/buku2HoC3yFNy/g8cD3wQ2ARUiv3DznQzus5d8BtOUmbkzomv0daameHPCzvWNIdZz2B2yJiLMwbEvY54IBbh9yRtgCLiHuB7wM/krRPRMwh5RBfAO4pCLT+OtRCjYZ+LQXsReow24g0B+5qpBnbJkfE3eEVkRcYbuku4CJilKQ5wGl5/OiVwLWVrletktQjIj7MIw+2BgYAE4EppDXNDo6I5yT9AOgFLE3uULMFg4OuERF35o6bsySNAd7xHWgtl4eC/U3S+cBzpPlw/0lakn4isAnwVr7LbABpeSNP9r6AcUeazSMv1d1mkr5HmhVsFjA8t2r3JQXZ5Ugzh/0LuCYibq5YRa1iHHTN2pmk7Ug3j/w2Is7N3yL2AtYgjdG9KCJm+dbeBZM70szaWV6y6CDgwIIOyutJY6FvjYhZeT8H3AWQW7pmHUTSd4HTgPNzB6WZg65ZR5K0K3AWaTy0OyjNQdeso7mD0go56JqZlZE70szMyshB18ysjBx0zczKyEHXzKyMHHStqkiaK2m8pBck3ZTnM2jtuQZLGp0f7yppeJF9e0r6aSuucbKkY0stb7TPFZL2aMG1Bkh6oaV1tOrioGvV5tOIGBQRA4H/AocVvqikxf9uI2JURJxVZJeeQIuDrllLOehaNXsEWDW38F6U9GfgGWAFSdtLelzSM7lF3B1A0o6SXpL0KGmuYHL5gZL+lB/3kXSrpOfytinpBoZVciv73LzfLyU9Jel5SacUnOvXkiZJuo80n0JRkn6Sz/OcpFsatd6/I+kRSS9LGpL37yzp3IJrH9rWD9Kqh4OuVaU8ScxOwIRctAZwVUSsD3wMnAB8JyK+CTwN/ELSIqQlzXchzea17HxOfz7wUESsB3yTNO3icOC13Mr+paTtSRONbwQMAjaQtKWkDYC9gfVJQf1bJbydv0bEt/L1XgQOLnhtALAVsDNwUX4PBwPvR8S38vl/ImmlEq5jNcDz6Vq16SZpfH78CHApaUrENxqWswG+DawNPJaWE2Nh4HHSisaTI+IVAEkjgUOauMY2wAEwb/mh9/PKu4W2z9uz+Xl3UhDuQZq05pN8jVElvKeBkk4npTC6A/cUvHZjvjX4FUn/yu9he2DdgnzvEvnaXu6+DjjoWrX5NCIGFRbkwPpxYREwJiL2abTfIKC9brEUaSXevzS6xs9acY0rgN3z3LoHAoMLXmt8rsjX/p+IKAzOSBrQwutaFXJ6wWrRWGAzSatCWrFB0urAS8BKklbJ++0zn+PvBw7Px3aWtDjwIakV2+Ae0tpxDbni5ZWWpX8Y+J6kbpJ6kFIZzekBTMkrRuzX6LU9JXXKdV6ZNP3jPcDheX8krS5psRKuYzXALV2rORExPbcYr5PUNRefEBEvSzqEtGTODOBRYGATpzgauFjSwcBc4PCIeFzSY3lI1l05r7sW8HhuaX8EDI2IZyTdAIwH3iClQJrzG+CJvP8EvhrcJwEPAX2AwyLiM0n/j5TrfUbp4tOB3Uv7dKzaecIbM7MycnrBzKyMHHTNzMrIQdfMrIwcdM3MyshB18ysjBx0zczKyEHXzKyM/j9Vj2KDIZAA6AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading A Confusion Matrix\n",
    "\n",
    "Looking at the plot of the confusion matrix, we have the predicted labels on the x-axis and the true labels on the y-axis. The blue cells running from the top left to bottom right contain the number of samples that the model accurately predicted. The white cells contain the number of samples that were incorrectly predicted.\n",
    "\n",
    "There are 420 total samples in the test set. Looking at the confusion matrix, we can see that the model accurately predicted 391 out of 420 total samples. The model incorrectly predicted 29 out of the 420.\n",
    "\n",
    "For the samples the model got correct, we can see that it accurately predicted that the patients would experience no side effects 191 times. It incorrectly predicted that the patient would have no side effects 10 times when the patient did actually experience side effects.\n",
    "\n",
    "On the other side, the model accurately predicted that the patient would experience side effects 200 times that the patient did indeed experience side effects. It incorrectly predicted that the patient would have side effects 19 times when the patient actually did not experience side effects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save And Load A Model with tf.keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can save model in different ways.\n",
    "\n",
    "#### 1. Saving And Loading The Model In Its Entirety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cheack first to see if the file exist already.\n",
    "#If not, the model is saved to disk.\n",
    "\n",
    "import os.path\n",
    "\n",
    "if os.path.isfile(\"models/medical_trial_model.h5\") is False:\n",
    "    \n",
    "    model.save(\"models/medical_trial_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "new_model = load_model('models/medical_trial_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~We can verify that the loaded model has the same architecture and weights as the saved model by calling summary() and get_weights() on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This save function saves:\n",
    " \n",
    "  * The arcitecture of the model, allowing to re-create the model.\n",
    "  * The wieghtd of the model.\n",
    "  * The training configuration(loss,optimizer).\n",
    "  * The state of the optimizer, allowing to remuse trainign  exactly where you left off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Saving And Loading Only The Architecture Of The Model\n",
    "\n",
    "We can do this by calling model.to_json(). This will save the architecture of the model as a JSON string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential\", \"layers\": [{\"class_name\": \"Dense\", \"config\": {\"name\": \"dense\", \"trainable\": true, \"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"units\": 16, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 32, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_2\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 2, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}], \"build_input_shape\": [null, 1]}, \"keras_version\": \"2.3.0-tf\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_string = model.to_json()\n",
    "json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "model_architecture = model_from_json(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_architecture.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, we can also use this same approach to saving and loading the model architecture to and from a YAML string. To do so, we use the functions to_yaml() and model_from_yaml() in the same fashion as we called the json functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  4. Saving And Loading The Weights Of The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this by calling model.save_weights() and passing in the path and file name to save the weights to with an h5 extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('models/my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a later point, we could then load the saved weights in to a new model, but the new model will need to have the same architecture as the old model before the weights can be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "    Dense(units=16, input_shape=(1,), activation='relu'),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dense(units=2, activation='softmax')\n",
    "])\n",
    "\n",
    "model2.load_weights('models/my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weâ€™ve now seen how to save only the weights of a model and deploy those weights to a new model, how to save only the architecture and then deploy that architecture to a model, and how to save everything about a model and deploy it in its entirety at a later time. Each of these saving and loading mechanisms may come in useful in differing scenarios.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
